---
title: "Why Risk it, When You Can {rix} it: A Tutorial for Reproducibility Focused on Simulation Studies"
shorttitle: "Reproducibility with rix"
author:
  - name: Felipe Fontana Vieira
    corresponding: true
    email: felipe.fontanavieira@ugent.be
    affiliations:
      - name: Ghent University 
        department: Department of Data Analysis 
  - name: Jason Geller
    affiliations:
      - name: Boston College
        department: Department of Psychology and Neuroscience
  - name: Bruno Rodrigues
    affiliations:
      - name: Ministry of Research and Higher Education, Luxembourg
        department: Statistics and Data Strategy Departments
abstract: |
  Reproducibility remains limited in psychology, in part because
  reproducibility exists on a spectrum -- from sharing isolated code fragments 
  to providing fully executable pipelines that ensure identical results.
  This article demonstrates how Nix and the {rix} R package provide a 
  comprehensive solution for achieving full computational reproducibility in 
  simulation studies.
keywords: [reproducibility, Nix, simulation studies, R, computational methods]
word-count: true
authornote: |
  Author contributions: [Add contributions]
  
  Correspondence concerning this article should be addressed to [Name], [Address]. 
  Email: [email]
format:
  apaquarto-pdf:
    documentmode: man
    keep-tex: true
    include-in-header:
      text: |
        \raggedbottom
  apaquarto-html: default
  
bibliography: references.bib
---

```{r}
#| label: load-packages
#| echo: false
#| message: false

library(ggplot2)
library(knitr)
library(cowplot)
library(dplyr)

```

Reproducibility remains limited in psychological science, in part because reproducibility operates along a continuum rather than as a binary property [@peng_2011]. At the lower end of this continuum, researchers share only their manuscript. Further along the spectrum, they may provide fragments of code, complete scripts, or publicly hosted datasets. At the upper end, researchers document a fully specified computational environment that enables others to regenerate identical results from raw data through the final manuscript.

In this article, we use *computational environment* to refer to the complete software context required for an analysis to run successfully. This includes the version of the programming language (e.g., R 4.3.3), the versions of all required packages, the system libraries that those packages rely on, and the operating system under which the analysis executes [@rodrigues_2023]. Crucially, these components interact: a package version may require a specific system library; a system library may behave differently across operating systems; and certain analyses rely on features available only in particular language versions. We therefore define *computational environment reproducibility* as the ability to reconstruct this entire software stack—language, packages, system libraries, and operating system—on any machine and at any future time, such that executing the same code yields the same numerical results. Environment reproducibility is foundational, because even perfectly documented code cannot be executed reliably if its surrounding software context is unspecified or cannot be recreated. Prior work emphasizes that reproducible research requires more than the availability of code and data; it also requires controlling software dependencies, relying on open-source tools, and ensuring access to the outputs that substantiate reported claims [@rodrigues_2023; @peikert_brandmaier_2021; @ziemann_etall_2023; @wiebels_moreau_2021; @epskamp_2019; @siepe_etall_2024]. Yet empirical assessments show that current practice falls short of these ideals. For example, @siepe_etall_2024 report that nearly two-thirds of simulation studies in psychology provide no accompanying code, and among those that do, documentation of the computational environment is rarely included. This gap is consequential: simulation studies inform methodological recommendations, meaning that insufficient reproducibility undermines confidence in those recommendations [@white_etall_2024].

Open-science initiatives have encouraged more transparent research practices. Journal incentives such as open-science badges [@kidwell_etall_2016], together with platforms like GitHub and the Open Science Framework, have made data [@levenstein_lyle_2018] and code sharing increasingly routine. However, as mentioned, data and code availability alone does not ensure that code will run. This is because code is never self-sufficient; it depends on a hierarchy of software components known collectively as dependencies. Dependencies include the version of the programming language, the set of packages used by the analysis, and the system libraries that those packages require in order to function correctly. If any dependency differs from the one used in the original analysis, the code may fail, behave differently across machines, or yield conflicting numerical results [@baker_etall_2024; @hodges_etall_2023; @glatard_etall_2015; @nosek_etall_2022]. For this reason, dependency management is an indispensable component of reproducibility.

Researchers currently navigate a fragmented landscape of tools, each addressing only part of this environment problem. Package-level managers such as {renv} [@ushey_2024], {groundhog} [@simonsohn_2020], and {rang} [@chan_2023] stabilize R package versions but do not manage the R interpreter itself or the system-level libraries those packages depend on. Documentation tools such as sessionInfo() record aspects of the environment but do not allow users to reconstruct it. Meanwhile, workflow orchestration tools—including {targets} [@landau_2021] and Make [@feldman_1979]—support reproducibility in a different sense: they specify the structure of an analysis by formalizing the order in which steps should run and by tracking dependencies among intermediate results. These tools clarify how an analysis proceeds, but they assume that the software stack required to run each step is already stable.

Containerization tools such as Docker and the Rocker project [@boettiger_2015; @boettiger_eddelbuettel_2017] offer a more comprehensive approach by bundling the full environment—operating system, system libraries, interpreter versions, and packages—into a single executable image. Containers thus solve an important part of the environment reproducibility problem. Yet their use requires familiarity with Linux system administration, including writing robust Dockerfiles, managing external repositories, and understanding image layering [@wiebels_moreau_2021]. Moreover, even containerization has limitations: as @malka2024 show, Dockerfiles often rely on mutable upstream repositories, meaning that rebuilding the same Dockerfile at a later time may not yield an identical environment. Containerization therefore improves reproducibility across machines but does not always ensure reproducibility across time.
These challenges are compounded by the increasing complexity of modern psychological research. Many contemporary analyses involve more than one programming language (e.g., R and Python) and often incorporate system-level tools such as Quarto for manuscript generation. Coordinating dependencies across these heterogeneous components stretches existing tools beyond their intended scope. Researchers thus face a difficult choice between solutions that are accessible but incomplete or approaches that are powerful but demand substantial technical expertise.

In this article, we focus specifically on computational environment reproducibility as the foundation upon which other reproducibility practices depend. We introduce Nix [@dolstra_etall_2004], a functional package manager designed to make software installation deterministic—even across machines and over long time spans—and {rix} [@rodrigues_baumann_2025], an R interface that allows researchers to use Nix without needing deep knowledge of its underlying language or infrastructure. Our objective is not to introduce a specific workflow orchestration system or to prescribe a particular analytic structure. Instead, we aim to show how Nix and {rix} can establish a stable, cross-platform environment within which any analysis—whether organized through simple, documented script sequences using `source()` or through more formal orchestration tools—can be executed reliably.

We illustrate these ideas through a reproducible simulation study conducted in R via RStudio, culminating in an automated APA-formatted manuscript generated with apaquarto [@schneider_2024]. Although the example centers on R because of its prominence in psychological methodology, the principles underlying environment reproducibility apply equally to other languages, including Python and Julia, and to development environments such as VS Code, Emacs, or Positron. Later in the article, we briefly comment on {rixpress}, which extends Nix-based reproducibility to workflows requiring more sophisticated coordination across languages. Unlike {targets}, which is limited to R-based workflows, {rixpress} is designed for polyglot pipelines. This distinction is conceptually relevant, but workflow orchestration is not the focus of the present tutorial, which assumes a basic, documented execution order for scripts. Throughout, our emphasis remains squarely on the reproducibility of computational environments as the essential basis for transparent, reliable, and durable scientific workflows.

# Nix and {rix}: A Comprehensive Solution

Nix is a package manager. That is, a system for installing and managing software. Unlike familiar tools such as `install.packages()` in R or `apt-get` on Linux, Nix addresses all four pillars of environment management—language versions, package versions, system dependencies, and cross-platform portability—through a fundamentally different approach [@rodrigues_baumann_2025]. Traditional package managers modify shared system directories, making installations depend on the existing state of the machine. Nix instead treats each environment as a fully specified, isolated configuration.

## Core Principles

Rather than installing software into global directories (e.g., `/usr/lib`), Nix places every package in its own directory under `/nix/store`. Each package path contains a cryptographic hash representing its precise inputs—source code, dependencies, and build instructions. Because these paths are content-addressed, multiple versions of the same software can coexist without conflict. A researcher can, for example, maintain projects requiring R 4.1.0 and R 4.3.3 side by side, or use different package versions across analyses, switching between them seamlessly [@rodrigues_baumann_2025].

The Nix ecosystem is built around nixpkgs, a version-controlled repository comprising more than 120,000 packages, including nearly all of CRAN and Bioconductor. By pinning a specific commit or date, researchers freeze the entire software stack—R itself, R packages, and all system libraries—at that point in time. This eliminates the system-dependency problems that tools like renv cannot address [@rodrigues_baumann_2025].

This architecture also ensures stability over time. Large-scale empirical work rebuilding over 700,000 packages from historical nixpkgs snapshots shows rebuildability rates above 99% and bit-for-bit reproducibility between 69–91%, demonstrating strong protection against temporal drift. Combined with binary caches, which often allow environments to materialize in seconds, Nix becomes practical for interactive research workflows [@rodrigues_baumann_2025].

## The {rix} Package: R Interface to Nix

Nix expressions are written in a dedicated functional language unfamiliar to most researchers. The {rix} package removes this barrier by providing an R-native interface. A single call to `rix()` generates complete Nix configurations from standard R syntax, specifying R versions, CRAN packages, system libraries, and even Python or Julia components when required. Users never need to read or write Nix code directly, as {rix} performs the translation automatically [@rodrigues_baumann_2025].

A key feature of {rix} is its integration with rstats-on-nix, a community-maintained fork offering daily CRAN snapshots and weekly tested environments on Linux and macOS. Researchers can request, for example, `rix(date = "2024-12-14")` to obtain a validated and reproducible environment without manually assessing compatibility. After the configuration is generated, `nix_build()` instantiates the environment, and binary caches typically allow this to complete within seconds [@rodrigues_baumann_2025].

Although Nix is capable of replacing tools like Docker for isolation or {renv} for package management, it does not require an all-or-nothing transition. Researchers can adopt it gradually and use it alongside familiar tooling—for instance, by building Docker images with Nix, converting existing {renv} lockfiles, or running {targets} pipelines within a Nix-defined environment. This allows Nix to strengthen reproducibility while preserving established workflows. For projects requiring more sophisticated pipeline management, {rixpress} extends Nix’s guarantees to workflow orchestration, enabling step-level isolation across languages, though such capabilities lie beyond the present focus on environment reproducibility. We will come back to this after the tutorial.

# A Practical Example: Setting Up a Reproducible Simulation Study with {rix}

Before proceeding with the technical implementation and tutorial, we refer readers to Appendix A, which outlines a common simulation study scenario^[Note that the rationale, programming-related choices (e.g., package choices), and results should not be used for substantial interpretation. However, we do highlight useful information that are based on recommendations for simulation studies [@siepe_etall_2024; @morris_etall_2019; @white_etall_2024] (see Computational Details in Appendix A).]. This will serve as a guiding example. Simulation studies in psychology typically structure code into multiple component files, each handling a distinct analytical phase. Our implementation follows this convention, organizing the workflow into five sequential files: data generation function (`01_data_generation.R`), statistical model specification (`02_models.R`), simulation execution (`03_run_simulation.R`), performance metric calculation (`04_performance_metrics.R`), and result visualization (`05_plots.R`). The simulation script (`03_run_simulation.R`) sources the data generation and model functions, executes the Monte Carlo replications, and saves results. The subsequent scripts read these saved results to compute performance metrics and generate visualizations. For convenience, we provide a master script (`06_run_all.R`) that loads all required packages and executes the complete workflow sequentially. Note that such sequential structures could benefit from explicit workflow orchestration tools like {targets} (Landau, 2021) and a clear documentation^[For instance, in this context, we use parallel processing which requires specifying the amount of cores to be used. This type of information should be mentioned.].

## Step I: Installing Nix and {rix}

It is possible to use {rix} to generate Nix expressions even without having Nix installed on your system. Think of it like writing a recipe without needing a kitchen—{rix} helps you document exactly what ingredients are needed (e.g., which R version, which packages, which system dependencies), but you need Nix (the kitchen) to actually cook the meal. This separation means you could write the configuration for a reproducible environment on one machine and build it on another. However, to actually build and use these environments, you need Nix installed.

### Installing Nix

Installation procedures vary by platform:

**Linux:** Open a terminal and run the Determinate Systems installer:
\small
```bash
curl --proto '=https' --tlsv1.2 -sSf \
    -L https://install.determinate.systems/nix | \
     sh -s -- install
```
\normalsize

**Windows:** First, ensure WSL2 is installed. Run as administrator in PowerShell:
\small
```powershell
wsl --install
```
\normalsize

Then activate systemd in your WSL2 Ubuntu environment by editing `/etc/wsl.conf`:
\small
```bash
sudo nano /etc/wsl.conf
```
\normalsize

Add these lines:
\small
```
[boot]
systemd=true
```
\normalsize

Save and restart WSL with `wsl --shutdown` in PowerShell. Finally, install Nix using the same Linux command above.

**macOS:** Open a terminal and run:
\small
```bash
curl --proto '=https' --tlsv1.2 -sSf \
    -L https://install.determinate.systems/nix | \
     sh -s -- install
```
\normalsize

For all the above platforms, after installation, configure the `rstats-on-nix` binary cache to speed up environment builds:
\small
```bash
nix-env -iA cachix -f https://cachix.org/api/v1/install
cachix use rstats-on-nix
```
\normalsize

We highlight suggest consulting the {rix} documentation for a more comprehensive platform-specific instructions, troubleshooting guidance, and additional configuration details: <https://docs.ropensci.org/rix/articles/b1-setting-up-and-using-rix-on-linux-and-windows.html> (Linux/Windows) and <https://docs.ropensci.org/rix/articles/b2-setting-up-and-using-rix-on-macos.html> (macOS).

## Installing {rix}

The method for installing {rix} depends on whether you already have R installed on your system. If you have R installed, you can install {rix} the usual way. For the CRAN version:
\small
```
install.packages("rix")
```
\normalsize

While for the development version:
\small
```
install.packages("rix", repos = c("https://ropensci.r-universe.dev"))
```
\normalsize

Once {rix} is installed, you can use it to generate `default.nix` files for your projects, which you then build with Nix. This latter part is explained in the next subsection (i.e., Specifying the Computational Environment). This tutorial will be focused on this scenario.

However, note that if you have installed Nix but do not yet have R on your system, or if you prefer to work entirely within the Nix ecosystem from the start, you can obtain both R and {rix} directly through Nix without installing R through the "traditional" means. The simplest approach is to create a temporary Nix shell that includes both R and {rix} by running this command in your terminal:
\small
```bash
nix-shell --expr "$(curl -sl 
  https://raw.githubusercontent.com/ropensci/rix/main/inst/extdata/default.nix)"
```
\normalsize

This creates an ephemeral environment where R and the development version of {rix} are immediately available. You can then start R within this shell, use {rix} to generate your project's `default.nix` file, and exit. Alternatively, if you prefer the stable CRAN version of {rix}, you can create a temporary shell with 
\small
```bash
nix-shell -p R rPackages.rix
```
\normalsize

Note that the {rix} documentation recommends managing R versions exclusively through Nix rather than mixing system-installed R with Nix-managed environments for optimal reproducibility, though both approaches are supported.

## Step II: Specifying the Computational Environment

The initial step in establishing a reproducible environment is to create a script that will generate the environment specification. We recommend creating a file named `generate_env.R` (or similar) in the project directory. This script will use the `rix()` function from the {rix} package to produce a `default.nix` file—a declarative specification that precisely defines all software dependencies required for the project.

For our simulation study, we implement the following environment specification, which can be found on the GitHub repository as a file named `generate_env.R`:

\small
```{r}
#| eval: false
#| echo: true
#library(rix)
rix(
  date = "2025-08-25",
  r_pkgs = c("rix", "quarto", "knitr", 
             "marginaleffects", "simhelpers", "ggplot2",
             "doParallel", "doRNG", "cowplot",
             "dplyr"),
  system_pkgs = c("quarto"),
  ide = "rstudio",
  project_path = ".",
  overwrite = TRUE
)
```
\normalsize

### The Environment Generation Script

The `rix()` function constructs this specification through a series of parameters that collectively describe the computational environment. Each parameter serves a distinct purpose in defining the environment's characteristics.

**Specifying the R version.** Researchers must first determine which version of R to use. This can be accomplished in two ways: The `r_ver` parameter accepts an exact version string (e.g., "4.3.3") or special designations such as "latest-upstream" for the most recent stable release. Alternatively, the `date` parameter specifies a particular date (e.g., "2024-11-15"), which ensures that R and all packages correspond to the versions available on that date. The date-based approach is generally preferable for reproducibility, as it captures a complete snapshot of the R ecosystem at a single point in time. For this tutorial, we use the `date` parameter to ensure temporal consistency across all software components.

**Declaring R package dependencies.** The `r_pkgs` parameter accepts a character vector listing all required R packages by their CRAN names. These packages will be installed from the version repository corresponding to the specified date or R version. It is important to list all packages that the analysis will load directly; dependencies of these packages are automatically resolved by Nix. For packages requiring specific versions not corresponding to the chosen date, researchers can specify exact versions using the syntax `"packagename@version"` (e.g., `"ggplot2@2.2.1"`). For packages available only on GitHub or other Git repositories, the `git_pkgs` parameter accepts a list structure containing repository URLs and specific commit hashes (see vignette `d1-installing-r-packages-in-a-nix-environment` for details). This ensures that exact development versions are obtained, which is particularly valuable when collaborating with package developers or requiring unreleased features.

**Including system-level dependencies.** Many R-based workflows require tools beyond R packages. The `system_pkgs` parameter specifies system-level software such as Quarto for document generation, Git for version control, or Pandoc for document conversion. The `tex_pkgs` parameter, similarly, lists LaTeX packages needed for PDF compilation. These can be added as needed for specific document formatting requirements. Critically, we include Quarto as a system package because this tutorial demonstrates full computational reproducibility—not merely of the simulation code, but of the complete manuscript itself. Our manuscript uses the `apaquarto` extension for APA formatting, stored in the project's `_extensions/` directory. Quarto extensions do not require explicit declaration in the Nix specification; when the `_extensions/` folder is committed to the repository, users building the environment automatically have access to these extensions.

**Multi-language environment support.** While this tutorial focuses on R, researchers working across multiple programming languages can include Python or Julia in their environments. The `py_conf` parameter accepts a list specifying a Python version and required packages (e.g., `py_conf = list(py_version = "3.12", py_pkgs = c("polars", "pandas"))`). Similarly, `jl_conf` enables Julia package installation. This capability is particularly useful for projects requiring statistical computing in R alongside machine learning pipelines in Python or numerical optimization in Julia.

**Configuring the development environment.** The `ide` parameter determines whether an integrated development environment should be included. Setting `ide = "rstudio"` installs a project-specific version of RStudio within the Nix environment. Note that on macOS, RStudio is only available through Nix for R versions 4.4.3 or later (or dates after 2025-02-28); for earlier versions, alternative editors must be used. Other supported IDEs include Positron (`ide = "positron"`), a next-generation data science IDE based on VS Code architecture, Visual Studio Code (`ide = "code"`), and command-line tools such as Radian (`ide = "radian"`). Each IDE installed via Nix is project-specific and will not interfere with system-wide installations. Researchers preferring to use an already-installed editor can set `ide = "none"` and configure their editor to interact with Nix shells (see vignette `e-configuring-ide` for configuration details).

**Setting file output parameters.** The `project_path` parameter indicates where the `default.nix` file should be written ("." denotes the current directory), while `overwrite` controls whether an existing file should be replaced. Setting `print = TRUE` displays the generated specification in the console for immediate verification.

### Generating the Environment Specification

Executing this script—either by running `Rscript generate_env.R` from the terminal or by sourcing it from within R using `source("generate_env.R")`—generates the `default.nix` file. This file serves as the formal, machine-readable specification of the computational environment. Importantly, `rix()` automatically invokes `rix_init()`, which creates a project-specific `.Rprofile` file that prevents package library conflicts and disables `install.packages()` to maintain environment integrity.

## Step III: Building and Using the Reproducible Environment

Once the `default.nix` file has been generated, the next step is to build the environment and use it to reproduce either the simulation analyses or the complete manuscript. This section demonstrates both workflows.

### Building the Environment

From the terminal, navigate to the project directory containing the `default.nix` file and execute:
```bash
nix-build
```

This command builds the environment according to the specification. The first execution will download and install all required packages, which may take a few minutes depending on network speed and system resources. Subsequent builds use cached packages and complete in seconds. Upon successful completion, a symbolic link named `result` appears in the project directory, pointing to the constructed environment in the Nix store.

To activate the environment, run:
```bash
nix-shell
```

This command drops the user into a shell where all specified packages and tools are available. The shell prompt typically changes to indicate that a Nix environment is active (e.g., `[nix-shell:~/project]$`). If RStudio was specified via `ide = "rstudio"`, it can be launched from within this shell by typing `rstudio`, ensuring it uses the project-specific R installation and package library.

### Reproducing the Simulation

As described before, our example contains multiple scripts. For streamlined execution, we provide a master script (`06_run_all.R`) that runs all simulation:

\small
```{r}
#| eval: false
#| echo: true

# required packages
library(marginaleffects); library(simhelpers)
library(doParallel); library(doRNG); library(ggplot2)

# step 1: run simulation (sources 01 and 02)
cat("Step 1: Running simulation...\n")
source("03_run_simulation.R")

# step 2: calculate performance metrics
cat("\nStep 2: Calculating performance metrics...\n")
source("04_performance_metrics.R")

# step 3: generate plots
cat("\nStep 3: Generating plots...\n")
source("05_plots.R")
```
\normalsize

Thus, to reproduce the simulation from within the Nix shell:
```bash
Rscript 06_run_all.R
```

This executes the complete simulation sequentially: first running the Monte Carlo replications which save results to `sim_results.rds`, then computing performance metrics and saving the summary table to `performance_summary.rds`, and finally generating all figures. Alternatively, individual scripts can be executed separately. The key advantage of executing within `nix-shell` is that all dependencies—R version, packages, and system tools—match exactly those specified in `default.nix`. However, while this linear structure is straightforward for moderate-scale simulations, more complex workflows could benefit from orchestration tools like `targets` (Landau, 2021), which manage dependencies automatically and ensure reproducibility. We will come back to this in the article. 

### Reproducing the Complete Manuscript

Beyond reproducing computational results, the Nix environment enables full manuscript reproducibility. The manuscript source file (`article.qmd`) combines narrative text, executable code chunks, and references to simulation outputs. In our specific case, we do not integrate the simulation run itself in the manuscript. We just load the obtained performance measures and integrate the code chunks that produce the plots (see Figure 1). To render the manuscript:

```bash
quarto render article.qmd 
```

This command executes all code chunks within the manuscript, incorporates results and figures, and produces a formatted PDF following APA style guidelines via the `apaquarto` extension. Because Quarto is included as a system package in our Nix specification, this rendering occurs within the reproducible environment, ensuring consistent output regardless of the host system's configuration.

```{r}
#| label: load-results
#| echo: false
#| message: false

summary_table <- readRDS("Simulation_Scripts/performance_summary.rds")

```

```{r}
#| label: fig-performance
#| fig-cap: "Performance of ACE estimator across sample sizes and confounding severity. Panel A shows relative bias, Panel B shows relative RMSE, Panel C shows coverage probability of 95% confidence intervals (dashed line at nominal 0.95 level), and Panel D shows average confidence interval width. Results demonstrate that model misspecification induces systematic bias that persists across sample sizes, while increasing sample size improves precision but not accuracy under misspecification."
#| fig-width: 10
#| fig-height: 8
#| echo: false
#| warning: false

# aanel A: Relative Bias
p_rel_bias <- ggplot(summary_table,
                     aes(x = n, y = rel_bias,
                         color = confound_label, group = confound_label)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Relative Bias",
       color = "Confounding\nnon-linearity",
       title = "A. Relative Bias") +
  theme_minimal() +
  theme(legend.position = "none")

# panel B: Relative RMSE
p_rel_rmse <- ggplot(summary_table,
                     aes(x = n, y = rel_rmse,
                         color = confound_label, group = confound_label)) +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Relative RMSE",
       color = "Confounding\nnon-linearity",
       title = "B. Relative RMSE") +
  theme_minimal() +
  theme(legend.position = "none")

# panel C: Coverage
p_coverage <- ggplot(summary_table,
                     aes(x = n, y = coverage,
                         color = confound_label, group = confound_label)) +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "gray50") +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Coverage of 95% CI",
       color = "Confounding\nnon-linearity",
       title = "C. Coverage Probability") +
  coord_cartesian(ylim = c(0, 1)) +
  theme_minimal() +
  theme(legend.position = "none")

# panel D: CI Width
p_width <- ggplot(summary_table,
                  aes(x = n, y = width,
                      color = confound_label, group = confound_label)) +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Average CI Width",
       color = "Confounding\nnon-linearity",
       title = "D. Confidence Interval Width") +
  theme_minimal() +
  theme(legend.position = "none")

legend <- get_legend(
  p_rel_bias + theme(legend.position = "right")
)

# 2x2 grid 
plot_grid(
  plot_grid(p_rel_bias, p_rel_rmse, p_coverage, p_width, 
            ncol = 2, nrow = 2),
  legend,
  rel_widths = c(3, 0.4)
)
```

```{r}
#| label: tbl-results
#| tbl-cap: "Performance metrics for ACE estimator across simulation conditions"
#| echo: false

results_display <- summary_table %>%
  select(n, confound_label, rel_bias, rel_rmse, coverage, width) %>%
  mutate(
    `Sample Size` = n,
    `Confounding` = confound_label,
    `Relative Bias` = sprintf("%.3f", rel_bias),
    `Relative RMSE` = sprintf("%.3f", rel_rmse),
    `Coverage` = sprintf("%.3f", coverage),
    `CI Width` = sprintf("%.3f", width)
  ) %>%
  select(`Sample Size`, `Confounding`, `Relative Bias`, 
         `Relative RMSE`, `Coverage`, `CI Width`)

kable(results_display, align = "lccccc", row.names = FALSE)
```

# Additional Considerations for Advanced Workflows

[...]

# Discussion

[...]

{{< pagebreak >}}

# References

::: {#refs}
:::

{{< include appendix_a.qmd >}}
