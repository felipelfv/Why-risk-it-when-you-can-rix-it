---
title: "Why Risk it, When You Can {rix} it: A Tutorial for Computational Reproducibility Focused on Simulation Studies"
shorttitle: "Reproducibility with rix"
author:
  - name: Felipe Fontana Vieira
    corresponding: true
    email: felipe.fontanavieira@ugent.be
    affiliations:
      - name: Ghent University 
        department: Department of Data Analysis 
  - name: Jason Geller
    affiliations:
      - name: Boston College
        department: Department of Psychology and Neuroscience
  - name: Bruno Rodrigues
    affiliations:
      - name: Ministry of Research and Higher Education, Luxembourg
        department: Statistics and Data Strategy Departments
abstract: |
  Reproducibility remains limited in psychology, in part because reproducibility
  exists on a spectrum -- from sharing isolated code fragments to providing
  fully executable pipelines that ensure identical results. This article
  introduces Nix and the {rix} R package as a way to provide a comprehensive
  solution for achieving full computational reproducibility in simulation
  studies. Building on this, we also demonstrate a tutorial on how to use {rix}
  to obtain a reproducible manuscript using the apaquarto extension.

keywords: [reproducibility, Nix, simulation studies, R, computational methods]
word-count: true
authornote: |
  Author contributions: [Add contributions]

  Correspondence concerning this article should be addressed to [Name], [Address].
  Email: [email]
format:
  apaquarto-pdf:
    document-mode: man
    keep-tex: true
    include-in-header:
      text: |
        \raggedbottom
  apaquarto-html: default

bibliography: references.bib
---

```{r}
#| label: load-packages
#| echo: false
#| message: false

library(ggplot2); library(knitr)
library(cowplot); library(dplyr)

```

Psychological science is in the midst of a credibility revolution, which has
prompted substantial progress in how research is conducted and evaluated
[@vazire2018]. Yet, despite notable progress, a key cornerstone of science,
reproducibility (i.e., the ability to precisely reproduce the results of a study
or studies based on provided data, code, materials, and software/hardware)
remains limited [@hardwicke2020].

Open-science initiatives have encouraged more transparent research practices.
Journal incentives such as open-science badges [@kidwell_etall_2016], together
with platforms like GitHub and the Open Science Framework, have made data
[@levenstein_lyle_2018] and code sharing increasingly routine. However, these
efforts have largely focused on *what* is shared rather than *how* shared
materials can be executed in practice. Data and code are never self-sufficient;
they depend on a hierarchy of software components known collectively as
dependencies, including the version of the programming language, the set of
packages used by the analysis, and the system libraries that those packages
require in order to function correctly. When these dependencies differ from
those used in the original analysis, code may fail, behave differently across
machines, or yield conflicting numerical results [@baker_etall_2024;
@hodges_etall_2023; @glatard_etall_2015; @nosek_etall_2022].

A key challenge in addressing this gap is that reproducibility is not a binary
feature but instead exists along a continuum [@peng_2011]. At the lower end of
this continuum, researchers may share only their manuscript. Further along the
spectrum, they might provide partial code, full analysis scripts, or publicly
accessible datasets. At the highest level, researchers document a fully
specified computational environment that allows others to recreate identical
results—from raw data to final manuscript output—with minimal friction. These
issues are particularly acute for simulation studies, which rely on complex
codebases, versioned dependencies, and intricate software configurations
[@luijken_etall_2024; @siepe_etall_2024].

**A figure highlighting this might be good here (JG)**

**To be clarified: what "this" refers to? (FV)**

In this article, we use *computational environment* to refer to the complete
software context required for an analysis to run successfully. This includes the
version of the programming language (e.g., R 4.3.3), the versions of all
required packages, the system libraries that those packages rely on, and the
operating system under which the analysis executes [@rodrigues_2023]. Crucially,
these components interact: a package version may require a specific system
library; a system library may behave differently across operating systems; and
certain analyses rely on features available only in particular language
versions. We therefore define *computational environment reproducibility* as the
ability to reconstruct this entire software stack—language, packages, system
libraries, and operating system—on any machine and at any future time, such that
executing the same code yields the same numerical results. Environment
reproducibility is foundational, because even perfectly documented code cannot
be executed reliably if its surrounding software context is unspecified or
cannot be recreated.

Consistent with this definition, prior work emphasizes that reproducible
research requires more than the availability of code and data; it also requires
controlling software dependencies, relying on open-source tools, literate
programming, and ensuring access to the outputs that substantiate reported
claims [@rodrigues_2023; @peikert_brandmaier_2021; @ziemann_etall_2023;
@wiebels_moreau_2021; @epskamp_2019; @siepe_etall_2024]. Yet empirical
assessments show that current practice falls short of these ideals. For example,
@siepe_etall_2024 report that nearly two-thirds of simulation studies in
psychology provide no accompanying code, and among those that do, documentation
of the computational environment is rarely included. This gap is consequential:
simulation studies inform methodological recommendations, meaning that
insufficient reproducibility undermines confidence in those recommendations
[@luijken_etall_2024; @white_etall_2024].

These challenges may persist not because relevant tools are unavailable, but
because researchers must navigate a fragmented landscape of solutions, each
addressing only part of the computational environment. Package-level managers
such as {renv} [@ushey_2024], {groundhog} [@simonsohn_2020], and {rang}
[@chan_2023] stabilize R package versions but do not manage the R interpreter
itself or the system-level libraries those packages depend on. Conversely,
interpreter-level tools such as {rig} [@cite] focus on managing R versions but
do not address package or system dependencies. Documentation tools such
as`sessionInfo()` record aspects of the environment but do not allow users to
reconstruct it. Meanwhile, workflow orchestration tools, such as including
{targets} [@landau_2021] and Make [@feldman_1979], support reproducibility in a
different sense: they specify the structure of an analysis by formalizing the
order in which steps should run and by tracking dependencies among intermediate
results. These tools clarify how an analysis proceeds, but they assume that the
software stack required to run each step is already stable. Containerization
tools such as Docker and the Rocker project [@boettiger_2015;
@boettiger_eddelbuettel_2017] offer a more comprehensive approach by bundling
the full environment—operating system, system libraries, interpreter versions,
and packages—into a single executable image. Containers thus solve an important
part of the environment reproducibility problem. Yet their use requires
familiarity with Linux system administration, including writing Dockerfiles,
managing external repositories, and understanding image layering which may be
perceived as "daunting" for some researchers [@wiebels_moreau_2021]. Moreover,
even containerization has limitations: as @malka2024 show, Dockerfiles often
rely on mutable upstream repositories, meaning that rebuilding the same
Dockerfile at a later time may not yield an identical environment.
Containerization therefore improves reproducibility across machines but does not
always ensure reproducibility across time.

Moreover, these challenges are compounded by the increasing complexity of modern
psychological research. Many analyses involve more than one programming language
(e.g., R and Python) and often incorporate system-level tools such as Quarto for
manuscript generation, which in turn rely on external components such as LaTeX
distributions whose versions and installed packages can vary substantially
across systems. Coordinating dependencies across these heterogeneous components
stretches existing tools beyond their intended scope. Researchers thus face a
difficult choice between solutions that are accessible but incomplete or
approaches that are powerful but demand substantial technical expertise,
especially for the integration of those tools.

In this article, we focus specifically on computational environment
reproducibility as the foundation upon which other reproducibility practices
depend. For that, we introduce Nix [@dolstra_etall_2004], a functional package
manager designed to make software installation deterministic, and {rix}
[@rodrigues_baumann_2025], an R interface that allows researchers to use Nix
without needing deep knowledge of its underlying language or infrastructure. Our
objective is not to introduce a specific workflow orchestration system or to
prescribe a particular analytic structure. Instead, we aim to show how Nix and
{rix} can establish a stable, cross-platform environment within which any
analysis—whether organized through simple, documented script sequences using
`source()` or through more formal orchestration tools—can be executed reliably.

We illustrate these ideas through a reproducible simulation study conducted in R
(Example 1), culminating in an automated APA-formatted manuscript generated with
apaquarto [@schneider_2024] (Example 2). Although the example centers on R
because of its prominence in psychological methodology, the principles
underlying environment reproducibility apply equally to other languages,
including Python and Julia, and to different development environments such as
RStudio, VS Code, Emacs, or Positron. Later in the article, we briefly comment
on {rixpress} [@rixpress], which extends Nix-based reproducibility to workflows
requiring more sophisticated coordination across languages. Unlike {targets},
which is limited to R-based workflows, {rixpress} is designed for polyglot
pipelines. This distinction is conceptually relevant, but workflow orchestration
is not the focus of the present tutorial, which assumes a basic, documented
execution order for scripts. Throughout, our emphasis remains squarely on the
reproducibility of computational environments as the essential basis for
transparent, reliable, and durable scientific workflows.

# A Practical Example: Setting up a Reproducible Simulation Study with {rix}

Before proceeding with the technical implementation and tutorial, we refer
readers to the Appendix A, which presents a simulation study scenario designed
to ground the subsequent discussion in a concrete example[^1]. The scenario
mimics a typical methods manuscript, describing both the statistical design and
the computational details one might encounter in practice. While the example is
illustrative rather than substantive—readers can follow the tutorial without
engaging with its particulars—we include it to anchor the discussion in
something more tangible.

Simulation studies typically structure code into multiple component files, each
handling a distinct analytical phase. Our implementation follows this
convention, organizing the workflow into five sequential files[^3]: data
generation function (`01_data_generation.R`), statistical model specification
(`02_models.R`), simulation execution (`03_run_simulation.R`), performance
metric calculation (`04_performance_metrics.R`), and results visualization
(`05_plots.R`). The simulation script (`03_run_simulation.R`) sources the data
generation and model functions, executes the Monte Carlo replications, and saves
results. The subsequent scripts read these saved results to compute performance
metrics and generate visualizations. For convenience, we provide a master script
(`06_run_all.R`) that loads all required packages and executes the complete
workflow sequentially. Note that such sequential structures could benefit from
explicit workflow orchestration tools and a clear documentation[^2]. Therefore,
this workflow depends on several R packages and more. The data generation
depends on the {rvinecopulib} package [@rvinecopulib]. The {marginaleffects}
provides the function for computing average causal effects [@marginaleffects].
The {dplyr} package is used for data wrangling [@dplyr] and {simhelpers}
supplies the functions for calculating the simulation performance metrics
[@simhelpers]. Parallel processing is handled by {doParallel} [@doParallel],
with {doRNG} [@doRNG] ensuring reproducible random number generation across
parallel workers. Visualization relies on {ggplot2} [@ggplot2] and {cowplot}
[@cowplot].

Now, suppose a researcher would have access to the .R files and attempts to run
the simulation. What might prevent them from obtaining identical results?. The
most immediate concern may involve package versions. A researcher installing
packages today may encounter errors if functions have been renamed or
deprecated, or may obtain results that differ subtly due to changes in
computational defaults. Beyond package versions, some R packages depend on
system-level libraries that must be installed separately from R itself. Our
simulation illustrates this directly: the {rvinecopulib} package provides an
interface to a C++ library and links against Boost, Eigen, and RcppThread
[@rvinecopulib]. Moreover, the R language itself introduces version
dependencies. Code written with R 4.3 may use syntax or functions unavailable in
R 4.0. More subtly, R's random number generator has changed across major
versions, meaning that identical code with identical seeds can produce different
random sequences depending on the R version. For simulation studies where
reproducibility of specific random draws matters, this version sensitivity is
consequential. Moreover, if one also employs literate programming for the
manuscript, additional dependencies arise: R Markdown or Quarto documents
require pandoc, and PDF output requires a LaTeX distribution—each with its own
versioning and platform-specific installation.

[^1]: Note that the rationale, programming-related choices, and results should
not be used for substantial interpretation. For instance, the usage of
{rvinecopulib} and the parallel set-up may be considered an overhead.

[^2]: For instance, in this context, we use parallel processing which requires
specifying the amount of cores to be used. This type of information should be
mentioned.

[^3]: Readers can find the files for these simulations here:
    <https://github.com/felipelfv/Why-risk-it-when-you-can-rix-it>

# Nix and {rix}: A Comprehensive Solution

Nix is a package manager built around declarative, isolated environments rather
than ad hoc system-level installations. Unlike familiar tools such as
`install.packages()` in R or `apt-get` on Linux, Nix manages language versions,
package versions, system dependencies, and cross-platform consistency through a
single framework [@rodrigues_baumann_2025]. Rather than modifying shared
directories, Nix builds each environment as an explicit, self-contained
specification. This addresses the fragmented landscape described before: where
researchers currently must coordinate separate tools for package management,
interpreter versions, and system dependencies, Nix handles all three within a
unified declarative model.

**Maybe compare Nix to renv and Docker to highlight what nix gives us (JG)**

## Core Principles

Rather than installing software into global directories (e.g., `/usr/lib`), Nix
places every package in its own directory under `/nix/store`. Each package path
contains a cryptographic hash representing its precise inputs—source code,
dependencies, and build instructions. Because these paths are content-addressed,
multiple versions of the same software can coexist without conflict. A
researcher can, for example, maintain projects requiring R 4.1.0 and R 4.3.3
side by side, or use different package versions across analyses, switching
between them seamlessly [@rodrigues_baumann_2025].

The Nix ecosystem is built around nixpkgs, a version-controlled repository
comprising more than 120,000 packages, including nearly all of CRAN and
Bioconductor. By pinning a specific commit or date, researchers freeze the
entire software stack—R itself, R packages, and all system libraries—at that
point in time. This eliminates the system-dependency problems that tools like
renv cannot address [@rodrigues_baumann_2025].

This architecture also ensures stability over time. Large-scale empirical work
rebuilding over 700,000 packages from historical nixpkgs snapshots shows
rebuildability rates above 99% and bit-for-bit reproducibility between 69–91%,
demonstrating strong protection against temporal drift. Combined with binary
caches, which often allow environments to materialize in seconds, Nix becomes
practical for interactive research workflows [@rodrigues_baumann_2025].

## The {rix} Package: R Interface to Nix

Nix expressions are written in a dedicated functional language unfamiliar to
most researchers. The {rix} package removes this barrier by providing an
R-native interface. A single call to `rix()` generates complete Nix
configurations from standard R syntax, specifying R versions, CRAN packages,
system libraries, and even Python or Julia components when required. Users never
need to read or write Nix code directly, as {rix} performs the translation
automatically [@rodrigues_baumann_2025].

A key feature of {rix} is its integration with rstats-on-nix, a
community-maintained fork offering daily CRAN snapshots and weekly tested
environments on Linux and macOS. Researchers can request, for example, `rix(date
= "2024-12-14")` to obtain a validated and reproducible environment without
manually assessing compatibility. After the configuration is generated,
`nix_build()` instantiates the environment, and binary caches typically allow
this to complete within seconds [@rodrigues_baumann_2025].

Although Nix is capable of replacing tools like Docker for isolation or {renv}
for package management, it does not require an all-or-nothing transition.
Researchers can adopt it gradually and use it alongside familiar tooling. For
instance, by building Docker images with Nix, converting existing {renv}
lockfiles, or running {targets} pipelines within a Nix-defined environment
[@rodrigues_baumann_2025]. This allows Nix to strengthen reproducibility while
preserving established workflows. For projects requiring more sophisticated
pipeline management, {rixpress} extends Nix’s guarantees to workflow
orchestration, enabling step-level isolation across languages, though such
capabilities lie beyond the present focus on environment reproducibility. We
will come back to this after the tutorial.

## Step I: Installing Nix and {rix}[^4]

[^4]: It is possible to use {rix} to generate Nix expressions even without
having Nix installed on your system. In practice, this means that you can write
a configuration (e.g., a `default.nix` file) without using Nix directly, but you
cannot build or enter the resulting environment unless Nix is installed
[@rodrigues_baumann_2025]. Think of it like writing a recipe without needing a
kitchen—{rix} helps you document exactly what ingredients are needed (e.g.,
which R version, which packages, which system dependencies), but you need Nix
(the kitchen) to actually cook the meal.

### Installing Nix

Installation procedures differ across systems, and we highly suggest readers to
consult the {rix} documentation and links therein for more information[^5].

[^5]: See: <https://docs.ropensci.org/rix/articles/b2-setting-up-and-using-rix-on-macos.html> and <https://docs.ropensci.org/rix/articles/b1-setting-up-and-using-rix-on-linux-and-windows.html>

#### Windows (via WSL2) 

On Windows, Nix runs inside the Windows Subsystem for Linux 2 (WSL2). To enable
WSL2, run the following in PowerShell as an administrator (@lst-enable-wsl):

::: {#lst-enable-wsl}
\small
```powershell
wsl --install
```
Enabling WSL2 on Windows
\normalsize
:::

After installing a Linux distribution (e.g., Ubuntu), it is recommended to
activate `systemd`, which improves compatibility with Nix. In your WSL2 Ubuntu
shell, edit `/etc/wsl.conf` (@lst-edit-wslconf):

::: {#lst-edit-wslconf}
\small
```bash
sudo -i
nano /etc/wsl.conf
```
Editing the WSL configuration file
\normalsize
:::

Then, this will open the `/etc/wsl.conf` in a nano (a command line text editor).
Add (@lst-systemd-config):

::: {#lst-systemd-config}
\small
```
[boot]
systemd=true
```
Enabling systemd in WSL2
\normalsize
:::

Next, save the file, then shut down WSL from PowerShell (@lst-shutdown-wsl):

::: {#lst-shutdown-wsl}
\small
```powershell
wsl --shutdown
```
Shutting down WSL2
\normalsize
:::

After shutting down WSL, launch your WSL2 Ubuntu environment again from the
Start menu.

#### Installing on Linux and Windows

Once your Linux or WSL2 environment is ready[^6], install Nix using the
Determinate Systems installer (@lst-install-nix-linux):

[^6]: Windows users who choose not to enable `systemd` may need to append
`--init none`; see {rix} documentation highlighted above.

::: {#lst-install-nix-linux}
\small
```bash
curl --proto '=https' --tlsv1.2 -sSf \
  -L https://install.determinate.systems/nix | \
  sh -s -- install
```
Installing Nix on Linux and Windows (WSL2)
\normalsize
:::

After installation, set up the `rstats-on-nix` binary cache, which provides
pre-built R packages and speeds up environment builds (@lst-cachix-linux): 

::: {#lst-cachix-linux}
\small
```bash
nix-env -iA cachix -f https://cachix.org/api/v1/install
cachix use rstats-on-nix
```
Configuring the rstats-on-nix binary cache on Linux/Windows
\normalsize
:::

Although {rix} includes a `setup_cachix()` helper, the {rix} documentation
recommends configuring the cache with the `cachix` client, as this properly
updates system-level files when needed.

#### Installing on macOS

On macOS, install Nix using the same Determinate Systems installer
(@lst-install-nix-macos):

::: {#lst-install-nix-macos}
\small
```bash
curl --proto '=https' --tlsv1.2 -sSf \
  -L https://install.determinate.systems/nix | \
  sh -s -- install
```
Installing Nix on macOS
\normalsize
:::

Then enable the `rstats-on-nix` binary cache (@lst-cachix-macos):

::: {#lst-cachix-macos}
\small
```bash
nix-env -iA cachix -f https://cachix.org/api/v1/install
cachix use rstats-on-nix
```
Configuring the rstats-on-nix binary cache on macOS
\normalsize
:::

### Installing {rix}

The method for installing {rix} depends on whether you already have R installed
on your system. If you have R installed, you can install {rix} as follows, which
is how we proceeded with this manuscript (@lst-install-rix):

\small
```{r}
#| lst-label: lst-install-rix
#| lst-cap: "Installing the {rix} package"
#| echo: true
#| eval: false

# CRAN version
install.packages("rix")
# Development version
install.packages("rix", repos = c("https://ropensci.r-universe.dev"))
```
\normalsize

Once {rix} is installed, you can use it to generate `default.nix` files for your
projects, which you then build with Nix. This latter part is explained in the
next subsection (i.e., [Specifying the Computational
Environment](#sec-specifying-environment)).

However, note that if you have installed Nix but do not yet have R on your
system, or if you prefer to work entirely within the Nix ecosystem from the
start, you can obtain both R and {rix} directly through Nix without installing R
through the "traditional" means. The simplest approach is to create a temporary
Nix shell that includes both R and {rix} by running this command in your
terminal (@lst-nix-shell-dev):

::: {#lst-nix-shell-dev}
\small
```bash
nix-shell --expr "$(curl -sl 
  https://raw.githubusercontent.com/ropensci/rix/main/inst/extdata/default.nix)"
```
Creating a temporary Nix shell with R and {rix} (development version)
\normalsize
:::

After downloading the necessary packages, an R session will start inside your
terminal. You can then use {rix} to generate your project's `default.nix` file
(again, see [Specifying the Computational
Environment](#sec-specifying-environment)). Alternatively, if you prefer the
stable CRAN version of {rix}, you can create a temporary shell with
(@lst-nix-shell-cran):

::: {#lst-nix-shell-cran}
\small
```bash
nix-shell -p R rPackages.rix
```
Creating a temporary Nix shell with R and {rix} (CRAN version)
\normalsize
:::

Note that the {rix} documentation recommends managing R versions exclusively
through Nix rather than mixing system-installed R with Nix-managed environments
for optimal reproducibility, though both approaches are supported (see the
following {rix} documentation:
<https://docs.ropensci.org/rix/articles/z-advanced-topic-walkthrough-project.html>).

## Step II: Specifying the Computational Environment {#sec-specifying-environment}

The initial step in establishing a reproducible environment is to create a
script that will generate the environment specification. We recommend creating a
file named `generate_env.R` (or similar) in the project directory. This script
will use the `rix()` function from the {rix} package to produce a `default.nix`
file—a declarative specification that precisely defines all software
dependencies required for the project.

For solely the simulation study (Example 1), we would implement the 
environment specification shown below (@lst-rix-env-sim-only):

\small
```{r}
#| lst-label: lst-rix-env-sim-only
#| lst-cap: "Environment specification for the simulation study using rix()"
#| eval: false
#| echo: true

library(rix)

rix(
  date = "2025-08-25", 
  r_pkgs = c( 
    "rix", "marginaleffects", "simhelpers",
    "ggplot2", "doParallel", "doRNG", "cowplot", "dplyr",
    "rvinecopulib"
  ),
  ide = "", 
  project_path = ".", 
  overwrite = TRUE 
)
```
\normalsize

In the case where we use literate programming for generating the manuscript
(Example 2), we implement the following environment specification, which can 
be found on the GitHub repository as a 
file named `generate_env.R` (@lst-rix-env-manuscript):

\small
```{r}
#| lst-label: lst-rix-env-manuscript
#| lst-cap: "Environment specification for the manuscript using rix()"
#| eval: false
#| echo: true

library(rix)

rix(
  date = "2025-08-25", # line 1
  r_pkgs = c( # line 2
    "rix", "quarto", "knitr", "marginaleffects", "simhelpers",
    "ggplot2", "doParallel", "doRNG", "cowplot", "dplyr", "svglite",
    "rvinecopulib"
  ),
  system_pkgs = c("quarto"), # line 3
  tex_pkgs = c( # line 4
    "amsmath", "ninecolors", "apa7", "scalerel", "threeparttable",
    "threeparttablex", "endfloat", "environ", "multirow", "tcolorbox",
    "pdfcol", "tikzfill", "fontawesome5", "framed", "newtx",
    "fontaxes", "xstring", "wrapfig", "tabularray", "siunitx",
    "fvextra", "geometry", "setspace", "fancyvrb", "anyfontsize"
  ),
  ide = "rstudio", # line 5
  project_path = ".", # line 6
  overwrite = TRUE # line 7
)
```
\normalsize

Note that we have more than just the R packages specified for the simulation
scripts. This happens because we also included what is needed for the manuscript
generation, not solely for the simulation code. In Appendix B, we mention more
specifically the reasons for adding each package in `r_pkgs()` and `tex_pkgs()`.
For now, we focus more on clarifying the different arguments for the `rix()`
function.

### The Environment Generation Script

The `rix()` function[^7] constructs this specification through a series of
parameters that collectively describe the computational environment. Each
parameter serves a distinct purpose in defining the environment's
characteristics.

[^7]: For an overarching information on the function `rix()`, we suggest the
following {rix} documentation: <https://docs.ropensci.org/rix/articles/c-using-rix-to-build-project-specific-environments.html>

#### Specifying the R version (line 1)

Researchers must first determine which version of R to use. This can be
accomplished in two ways: The `r_ver` argument accepts an exact version string
(e.g., "4.3.3") or special designations such as "latest-upstream" for the most
recent stable release. Alternatively, the `date` argument specifies a particular
date (e.g., "2024-11-15"), which ensures that R and all packages correspond to
the versions available on that date. The date-based approach is generally
preferable for reproducibility, as it captures a complete snapshot of the R
ecosystem at a single point in time. For this tutorial, as shown on top, we use
the `date` parameter to ensure temporal consistency across all software
components [@rodrigues_baumann_2025] (see {rix} documentation for more:
<https://docs.ropensci.org/rix/articles/d2-installing-system-tools-and-texlive-packages-in-a-nix-environment.html>).

#### Declaring R package dependencies (line 2)
The `r_pkgs` argument accepts a character vector listing all required R packages
by their CRAN names. These packages will be installed from the version
repository corresponding to the specified date or R version. It is important to
list all packages that the analysis will load directly; dependencies of these
packages are automatically resolved by Nix. For packages requiring specific
versions not corresponding to the chosen date, researchers can specify exact
versions using the syntax `"packagename@version"` (e.g., `"ggplot2@2.2.1"`). For
packages available only on GitHub or other Git repositories, the `git_pkgs`
argument accepts a list structure containing repository URLs and specific commit
hashes. For example:

\small
```{r}
#| lst-label: lst-git-pkgs-example
#| lst-cap: "Example for the git_pkgs argument"
#| eval: false
#| echo: true
git_pkgs = list(
    package_name = "marginaleffects",
    repo_url = "https://github.com/vincentarelbundock/marginaleffects",
    commit = "304bff91dc31ae28b227a8485bfa4f7bdc86d625"
)
```
\normalsize

This ensures that exact development versions are obtained
[@rodrigues_baumann_2025]. For our simulation study, all packages were used with
their CRAN versions (see {rix} documentation for more details:
<https://docs.ropensci.org/rix/articles/d2-installing-system-tools-and-texlive-packages-in-a-nix-environment.html>).

#### Including system-level dependencies (line 3)

Many R-based workflows require tools beyond R packages. The `system_pkgs`
parameter specifies system-level software such as Quarto for document
generation, Git for version control, or Pandoc for document conversion.
Critically, we include Quarto as a system package because this tutorial
demonstrates full computational reproducibility—not merely of the simulation
code, but of the complete manuscript itself. Our manuscript uses the `apaquarto`
extension for APA formatting, stored in the project's `_extensions/` directory
[@rodrigues_baumann_2025] (see {rix} documentation for more:
<https://docs.ropensci.org/rix/articles/d2-installing-system-tools-and-texlive-packages-in-a-nix-environment.html>).

#### Specifying LaTeX packages (line 4)

The `tex_pkgs` parameter specifies LaTeX packages needed for PDF compilation.
When any packages are listed, Nix automatically includes a minimal TexLive
distribution (`scheme-small`) as a base, to which the specified packages are
added. Determining the required LaTeX packages typically involves some trial and
error—Quarto's error messages during, for example, the PDF rendering indicate
which packages are missing, and these can then be added to `tex_pkgs` (see {rix}
documentation for more:
<https://docs.ropensci.org/rix/articles/d2-installing-system-tools-and-texlive-packages-in-a-nix-environment.html>).

#### Configuring the development environment (line 5)

The `ide` parameter determines whether an integrated development environment
should be included in the Nix environment. Setting `ide = "rstudio"` installs a
project-specific version of RStudio within the Nix environment. This is required
for RStudio because, unlike other editors, RStudio cannot interact with Nix
shells unless it is itself installed via Nix. Note that on macOS, RStudio is
only available through Nix for R versions 4.4.3 or later (or dates after
2025-02-28); for earlier versions, alternative editors must be used. Other
supported IDEs include Positron (`ide = "positron"`), Visual Studio Code (`ide =
"code"`), and command-line tools such as Radian (`ide = "radian"`). These
editors can either be installed within the Nix environment using the `ide`
parameter, or researchers can use an already-installed version by setting `ide =
"none"` (or `ide = "other"`) and configuring `direnv` to automatically load the
Nix environment when opening the project folder. Each IDE installed via Nix is
project-specific and will not interfere with system-wide installations. See the
{rix} documentation for detailed configuration instructions:
<https://docs.ropensci.org/rix/articles/e-configuring-ide.html>.

#### Setting file output parameters (line 6 and 7)

The `project_path` parameter indicates where the `default.nix` file should be
written ("." denotes the current directory), while `overwrite` controls whether
an existing file should be replaced. Adding to this, setting `print = TRUE`,
which is another argument, displays the generated specification in the console
for immediate verification [@rodrigues_baumann_2025].

#### Multi-language environment support

While this tutorial focuses on R, researchers working across multiple
programming languages can include Python or Julia in their environments. The
`py_conf` parameter accepts a list specifying a Python version and required
packages (e.g., `py_conf = list(py_version = "3.12", py_pkgs =
c("polars","pandas"))`). Similarly, `jl_conf` enables Julia package
installation. This capability is particularly useful, for example, for projects
requiring statistical computing in R alongside machine learning pipelines in
Python or numerical optimization in Julia [@rodrigues_baumann_2025] (see {rix}
documentation for more:
<https://docs.ropensci.org/rix/articles/d1-installing-r-packages-in-a-nix-environment.html>).

### Generating the Environment Specification

To execute the script for Example 2, either run from the terminal `Rscript
generate_env.R`, source it from within R using `source("generate_env.R")`, or
run the `rix::rix()` function above. This will generate the `default.nix` file
in the project directory. This file serves as the formal, machine-readable
specification of the computational environment. Importantly, `rix()`
automatically invokes `rix_init()`, which creates a project-specific `.Rprofile`
file that prevents package library conflicts and disables `install.packages()`
to maintain environment integrity. There may be exemptions to this, which we
comment briefly in the next section.

## Step III: Building and Using the Reproducible Environment

Once the `default.nix` file has been generated, the next step is to build the
environment and use it to reproduce either the simulation analyses or the
complete manuscript. This section demonstrates both workflows.

### Building the Environment

From the terminal, navigate to the study directory containing the `default.nix`
file and execute (@lst-nix-build):

::: {#lst-nix-build}
\small
```bash
nix-build
```
Building the Nix environment
\normalsize
:::

This command builds the environment according to the specification. The first
execution will download and install all required packages, which may take a few
minutes depending on network speed and system resources. Subsequent builds use
cached packages and complete in seconds. Upon successful completion, a symbolic
link named `result` appears in the project directory, pointing to the
constructed environment in the Nix store.

To activate the environment, run (@lst-nix-shell):

::: {#lst-nix-shell}
\small
```bash
nix-shell
```
Activating the Nix environment
\normalsize
:::

This command drops the user into a shell where all specified packages and tools
are available. The shell prompt typically changes to indicate that a Nix
environment is active (e.g., `[nix-shell:~/project]$`).

As mentioned, it is worth noting that Nix shells do not fully isolate you from
your existing system by default. For R users, this has a practical implication:
packages installed in your regular R library (outside of Nix) could potentially
be loaded when running R from within the Nix environment. The {rix} package
addresses this automatically—when you call `rix()`, it also executes
`rix_init()`, which creates a project-specific `.Rprofile`. This file configures
R to ignore external package libraries and also disables `install.packages()`
within the environment. The rationale is straightforward: any new packages
should be added to `default.nix` and the environment rebuilt, preserving full
reproducibility [@rodrigues_baumann_2025]. However, for stricter isolation[^8]
that also prevents access to other system programs not specified in
`default.nix`, use the `--pure` flag (@lst-nix-shell-pure):

[^8]: For example, when preparing this manuscript without the `--pure` flag,
`quarto render` worked successfully. However, when using the `--pure` flag, the
build failed. Running `quarto check` from within the Nix shell (i.e., `nix-shell
--run "quarto check"`) revealed that Quarto was still accessing the system's
LaTeX installation (`/Library/TeX/texbin`) rather than being restricted to only
what was specified in `default.nix`.

::: {#lst-nix-shell-pure}
\small
```bash
nix-shell --pure
```
Activating the Nix environment with strict isolation
\normalsize
:::

### Reproducing the Simulation (Example 1)

As described before, our Example 1 contains multiple scripts. For streamlined
execution, we provide a master script (`06_run_all.R`) that runs the complete
simulation and calculates the results as well as visualizations. The script
begins by loading the required packages, then proceeds through three steps:
first, it sources `03_run_simulation.R`, which in turn loads the data generation
function (`01_data_generation.R`) and the model estimation functions
(`02_models.R`) to run the Monte Carlo simulation; second, it sources
`04_performance_metrics.R` to calculate the performance criteria from the saved
simulation results; and third, it sources `05_plots.R` to generate the figures
(see @fig-performance). The script has the following content (@lst-run-all):

\small
```{r}
#| lst-label: lst-run-all
#| lst-cap: "Master script for running the complete simulation workflow"
#| eval: false
#| echo: true
#| message: false

library(marginaleffects); library(simhelpers); library(rvinecopulib)
library(doParallel); library(doRNG); library(ggplot2); library(cowplot); 
library(dplyr)

source("03_run_simulation.R")
source("04_performance_metrics.R")
source("05_plots.R")
```
\normalsize

Thus, to reproduce the simulation from within the Nix shell, meaning after
running nix-build and nix-shell (@lst-run-simulation):

::: {#lst-run-simulation}
\small
```bash
Rscript 06_run_all.R
```
Running the complete simulation workflow
\normalsize
:::

Alternatively, individual scripts can be executed separately (i.e., `Rscript
03_run_simulation.R)`). Therefore, the key advantage of executing within
`nix-shell` is that all dependencies—R version, packages, and system tools—match
exactly those specified in `default.nix`.

### Reproducing the Complete Manuscript (Example 2)[^9]

[^9]: See the {rix} documentation for more: <https://docs.ropensci.org/rix/articles/z-advanced-topic-building-an-environment-for-literate-programming.html>

Beyond reproducing computational results, the Nix environment enables full
manuscript reproducibility. The manuscript source file (`article.qmd`) combines
narrative text, executable code chunks, and references to simulation outputs. In
our specific case, we integrate the simulation run itself in the manuscript as
well as the reporting (i.e., performance metrics calculation and visualization).
In other words, the code in the separate .R files are included as code chunks
(see `article.qmd` in the GitHub repository).

This is not needed and most researchers would in fact probably not include the
simulation run itself in the manuscript as many simulations take days to be
completed. Thus, in this case, one could just proceed with the `Rscript
03_run_simulation.R` inside the nix shell. Then, in the `article.qmd` load the
obtained results and integrate the code chunks that produce the performance
metrics and visualization (see Figure 1).

To render the manuscript (@lst-quarto-render):

::: {#lst-quarto-render}
\small
```bash
quarto render article.qmd
```
Rendering the manuscript with Quarto
\normalsize
:::

This command executes all code chunks in the manuscript, incorporates results
and figures, and generates a formatted PDF following APA style guidelines via
the apaquarto extension [@schneider_2024]. This extension is saved in the
project repo already.

To download this extension for your own work you can install the extension by 
using the terminal (@lst-apaquarto-install):

::: {#lst-apaquarto-install}
\small
```bash
quarto use template wjschne/apaquarto
```
Installing the apaquarto extension
\normalsize
:::

or in the console (@lst-apaquarto-r):

\small
```{r}
#| lst-label: lst-apaquarto-r
#| lst-cap: "Installing the apaquarto extension from R"
#| eval: false
#| echo: true

quarto::quarto_use_template("wjschne/apaquarto")
```
\normalsize

The final document (.pdf or .html) is saved directly in the project folder.
Because Quarto is installed as a system-level package in our Nix specification,
the rendering occurs entirely within a fully reproducible environment, ensuring
consistent output across machines regardless of local software configurations.
If desired, the manuscript can also be reproduced interactively by opening the
project folder in the user’s preferred IDE and running the code chunks directly.

```{r}
#| lst-label: lst-load-results
#| lst-cap: "Loading the simulation results"
#| echo: false
#| message: false

summary_table <- readRDS("Simulation_Scripts/performance_summary.rds")
```

```{r}
#| lst-label: lst-fig-performance
#| lst-cap: "Code for generating the performance metrics visualization"
#| label: fig-performance
#| fig-cap: "Performance of ACE estimator across sample sizes and confounding severity. Panel A shows relative bias, Panel B shows relative RMSE, Panel C shows coverage probability of 95% confidence intervals (dashed line at nominal 0.95 level), and Panel D shows average confidence interval width. Results demonstrate that model misspecification induces systematic bias that persists across sample sizes, while increasing sample size improves precision but not accuracy under misspecification."
#| fig-width: 10
#| fig-height: 8
#| echo: false
#| warning: false

# aanel A: Relative Bias
p_rel_bias <- ggplot(summary_table,
                     aes(x = n, y = rel_bias,
                         color = confound_label, group = confound_label)) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray50") +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Relative Bias",
       color = "Confounding\nnon-linearity",
       title = "A. Relative Bias") +
  theme_minimal() +
  theme(legend.position = "none")

# panel B: Relative RMSE
p_rel_rmse <- ggplot(summary_table,
                     aes(x = n, y = rel_rmse,
                         color = confound_label, group = confound_label)) +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Relative RMSE",
       color = "Confounding\nnon-linearity",
       title = "B. Relative RMSE") +
  theme_minimal() +
  theme(legend.position = "none")

# panel C: Coverage
p_coverage <- ggplot(summary_table,
                     aes(x = n, y = coverage,
                         color = confound_label, group = confound_label)) +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "gray50") +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Coverage of 95% CI",
       color = "Confounding\nnon-linearity",
       title = "C. Coverage Probability") +
  coord_cartesian(ylim = c(0, 1)) +
  theme_minimal() +
  theme(legend.position = "none")

# panel D: CI Width
p_width <- ggplot(summary_table,
                  aes(x = n, y = width,
                      color = confound_label, group = confound_label)) +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Average CI Width",
       color = "Confounding\nnon-linearity",
       title = "D. Confidence Interval Width") +
  theme_minimal() +
  theme(legend.position = "none")

legend <- get_legend(
  p_rel_bias + theme(legend.position = "right")
)

# 2x2 grid 
plot_grid(
  plot_grid(p_rel_bias, p_rel_rmse, p_coverage, p_width, 
            ncol = 2, nrow = 2),
  legend,
  rel_widths = c(3, 0.4)
)
```

```{r}
#| lst-label: lst-tbl-results
#| lst-cap: "Code for generating the performance metrics table"
#| label: tbl-results
#| tbl-cap: "Performance metrics for ACE estimator across simulation conditions"
#| echo: false

results_display <- summary_table %>%
  select(n, confound_label, rel_bias, rel_rmse, coverage, width) %>%
  mutate(
    `Sample Size` = n,
    `Confounding` = confound_label,
    `Relative Bias` = sprintf("%.3f", rel_bias),
    `Relative RMSE` = sprintf("%.3f", rel_rmse),
    `Coverage` = sprintf("%.3f", coverage),
    `CI Width` = sprintf("%.3f", width)
  ) %>%
  select(`Sample Size`, `Confounding`, `Relative Bias`, 
         `Relative RMSE`, `Coverage`, `CI Width`)

kable(results_display, align = "lccccc", row.names = FALSE)
```

# Additional Considerations for Advanced Workflows

## Workflow Orchestration: {targets} and {rixpress}

Complex simulation studies often benefit from workflow management systems that
track dependencies between computational steps, cache intermediate results, and
enable selective re-execution when inputs change. Two complementary approaches
exist within the Nix ecosystem: using {targets} inside a Nix environment, or
using {rixpress} to leverage Nix itself as the build automation tool.

**Using {targets} within Nix.** As mentioned, the {targets} package
[@landau_2021] provides workflow orchestration for R-based projects. This
combination ensures both computational reproducibility (via Nix controlling the
environment) and computational efficiency (via targets' intelligent caching). To
integrate {targets} with Nix, simply include "targets" in the `r_pkgs` parameter
of `rix()`, and execute the pipeline within `nix-shell` using `Rscript -e
'targets::tar_make()'`. The {targets} metadata directory (`_targets/`) should be
excluded from version control while the `_targets.R` configuration file should
be committed alongside `default.nix` [@rodrigues_baumann_2025]. This approach is
ideal for projects that remain within the R ecosystem and do not require
different computational environments for different pipeline steps (see {rix}
documentation:
<https://docs.ropensci.org/rix/articles/z-advanced-topic-reproducible-analytical-pipelines-with-nix.html>).

**Using {rixpress} for polyglot pipelines.** The {rixpress} package [@rixpress],
a sister package to {rix}, uses Nix itself as the build automation tool rather
than operating within a Nix environment. Each pipeline step becomes a Nix
derivation, providing hermetic builds with sandboxed execution and
content-addressable caching. The key advantage of {rixpress} emerges in
multi-language workflows: different steps can execute in different Nix-defined
environments (e.g., one step using R 4.2.0 with specific packages, another using
Python 3.12 with machine learning libraries, another using Julia for numerical
optimization). The package interface, inspired by {targets}, uses functions like
`rxp_r()`, `rxp_py()`, and `rxp_jl()` to define pipeline steps, with automatic
serialization handling data transfer between languages. Objects are stored in
the Nix store and can be inspected interactively using helper functions like
`rxp_read()` and `rxp_load()` (see {rixpress} documentation:
<https://docs.ropensci.org/rixpress/articles/intro-concepts.html>).

## Converting Existing {renv} Projects

Many researchers have existing projects using {renv} for package management. The
`renv2nix()` function facilitates migration by reading an `renv.lock` file and
generating an equivalent Nix specification. This conversion is particularly
valuable for projects where {renv} encountered system dependency issues or where
stricter reproducibility guarantees are desired. However, researchers should
note that while {renv} snapshots R package versions, Nix additionally pins
system libraries and compilers, potentially exposing previously hidden
dependencies on system configuration [@rodrigues_baumann_2025] (see {rix}
documentation: <https://docs.ropensci.org/rix/articles/f-renv2nix.html>).

## Containerization with Docker

Institutions with existing Docker-based infrastructure may wish to combine Nix
with containers. While this might seem redundant—both technologies provide
isolation—the combination offers complementary benefits: Nix ensures
bit-reproducible builds across systems, while Docker provides a familiar
deployment mechanism for non-Nix-aware computing environments. The approach is
to use Nix as the base layer within a Docker container
[@rodrigues_baumann_2025]. This strategy is particularly relevant, for example,
for projects requiring deployment to cloud computing platforms or
high-performance computing clusters where Docker is the standard
containerization technology (see {rix} documentation:
<https://docs.ropensci.org/rix/articles/z-advanced-topic-using-nix-inside-docker.html>).

# Discussion


{{< pagebreak >}}

# References

::: {#refs}
:::

{{< include appendix_a.qmd >}}

{{< include appendix_b.qmd >}}
