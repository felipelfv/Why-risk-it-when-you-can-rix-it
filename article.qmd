---
title: "Why Risk it, When You Can {rix} it: A Tutorial for [Computational] Reproducibility Focused on Simulation Studies"
shorttitle: "Reproducibility with rix"
author:
  - name: Felipe Fontana Vieira
    corresponding: true
    email: felipe.fontanavieira@ugent.be
    affiliations:
      - name: Ghent University 
        department: Department of Data Analysis 
  - name: Jason Geller
    affiliations:
      - name: Boston College
        department: Department of Psychology and Neuroscience
  - name: Bruno Rodrigues
    affiliations:
      - name: Ministry of Research and Higher Education, Luxembourg
        department: Statistics and Data Strategy Departments
abstract: |
  Reproducibility remains limited in psychology, in part because
  reproducibility exists on a spectrum -- from sharing isolated code fragments 
  to providing fully executable pipelines that ensure identical results.
  This article introduces Nix and the {rix} R package as a way to provide a 
  comprehensive solution for achieving full computational reproducibility in 
  simulation studies. Building on this, we also demonstrate a tutorial on how to use {rix} to obtain a reproducible manuscript using the apaquarto extension.
  
keywords: [reproducibility, Nix, simulation studies, R, computational methods]
word-count: true
authornote: |
  Author contributions: [Add contributions]
  
  Correspondence concerning this article should be addressed to [Name], [Address]. 
  Email: [email]
format:
  apaquarto-pdf:
    documentmode: man
    keep-tex: true
    include-in-header:
      text: |
        \raggedbottom
  #apaquarto-html: default
  
bibliography: references.bib
---

```{r}
#| label: load-packages
#| echo: false
#| message: false

library(ggplot2)
library(knitr)
library(cowplot)
library(dplyr)

```

**Psychological science is in the midst of a credibility revolution, which has prompted substantial progress in how research is conducted and evaluated [@vazire2018]. Yet, despite notable progress, a key cornerstone of science, reproducibility (i.e., the ability to precisely reproducible the results of a study or studies based on provided data, code, materials, and software/hardware) remains limited** [@hardwicke2020]**. A key barrier is that reproducibility is not a binary feature but instead exists along a continuum [@peng_2011]. At the lower end of this continuum, researchers may share only their manuscript. Further along the spectrum, they might provide partial code, full analysis scripts, or publicly accessible datasets. At the highest level, researchers document a fully specified computational environment that allows others to recreate identical results—from raw data to final manuscript output—with minimal friction. These issues are particularly acute for simulation studies, which rely on complex codebases, versioned dependencies, and intricate software configurations [@luijken_etall_2024; @siepe_etall_2024].**

\[I think we need to be specific on terminology as I often see reproducibiity refer to replication and vice versa\]

\[A figure highlighting this might be good here\].

In this article, we use *computational environment* to refer to the complete software context required for an analysis to run successfully. This includes the version of the programming language (e.g., R 4.3.3), the versions of all required packages, the system libraries that those packages rely on, and the operating system under which the analysis executes [@rodrigues_2023]. Crucially, these components interact: a package version may require a specific system library; a system library may behave differently across operating systems; and certain analyses rely on features available only in particular language versions. We therefore define *computational environment reproducibility* as the ability to reconstruct this entire software stack—language, packages, system libraries, and operating system—on any machine and at any future time, such that executing the same code yields the same numerical results. Environment reproducibility is foundational, because even perfectly documented code cannot be executed reliably if its surrounding software context is unspecified or cannot be recreated.

Indeed, prior work emphasizes that reproducible research requires more than the availability of code and data; it also requires controlling software dependencies, relying on open-source tools, and ensuring access to the outputs that substantiate reported claims [@rodrigues_2023; @peikert_brandmaier_2021; @ziemann_etall_2023; @wiebels_moreau_2021; @epskamp_2019; @siepe_etall_2024]. Yet empirical assessments show that current practice falls short of these ideals. For example, @siepe_etall_2024 report that nearly two-thirds of simulation studies in psychology provide no accompanying code, and among those that do, documentation of the computational environment is rarely included. This gap is consequential: simulation studies inform methodological recommendations, meaning that insufficient reproducibility undermines confidence in those recommendations [@luijken_etall_2024; @white_etall_2024].

Open-science initiatives have encouraged more transparent research practices. Journal incentives such as open-science badges [@kidwell_etall_2016], together with platforms like GitHub and the Open Science Framework, have made data [@levenstein_lyle_2018] and code sharing increasingly routine. However, as mentioned, data and code are never self-sufficient; they depend on a hierarchy of software components known collectively as dependencies. Dependencies include the version of the programming language, the set of packages used by the analysis, and the system libraries that those packages require in order to function correctly. If any dependency differs from the one used in the original analysis, the code may fail, behave differently across machines, or yield conflicting numerical results [@baker_etall_2024; @hodges_etall_2023; @glatard_etall_2015; @nosek_etall_2022].

Researchers currently navigate a fragmented landscape of tools, each addressing only part of this environment problem. Package-level managers such as {renv} [@ushey_2024], {groundhog} [@simonsohn_2020], and {rang} [@chan_2023] stabilize R package versions but do not manage the R interpreter itself or the system-level libraries those packages depend on. Documentation tools such as `sessionInfo()` record aspects of the environment but do not allow users to reconstruct it. Meanwhile, workflow orchestration tools, such as including {targets} [@landau_2021] and Make [@feldman_1979], support reproducibility in a different sense: they specify the structure of an analysis by formalizing the order in which steps should run and by tracking dependencies among intermediate results. These tools clarify how an analysis proceeds, but they assume that the software stack required to run each step is already stable.

Containerization tools such as Docker and the Rocker project [@boettiger_2015; @boettiger_eddelbuettel_2017] offer a more comprehensive approach by bundling the full environment—operating system, system libraries, interpreter versions, and packages—into a single executable image. Containers thus solve an important part of the environment reproducibility problem. Yet their use requires familiarity with Linux system administration, including writing robust Dockerfiles, managing external repositories, and understanding image layering [@wiebels_moreau_2021]. Moreover, even containerization has limitations: as @malka2024 show, Dockerfiles often rely on mutable upstream repositories, meaning that rebuilding the same Dockerfile at a later time may not yield an identical environment. Containerization therefore improves reproducibility across machines but does not always ensure reproducibility across time.

Moreover, these challenges are compounded by the increasing complexity of modern psychological research. Many contemporary analyses involve more than one programming language (e.g., R and Python) and often incorporate system-level tools such as Quarto for manuscript generation. Coordinating dependencies across these heterogeneous components stretches existing tools beyond their intended scope. Researchers thus face a difficult choice between solutions that are accessible but incomplete or approaches that are powerful but demand substantial technical expertise.

In this article, we focus specifically on computational environment reproducibility as the foundation upon which other reproducibility practices depend. We introduce Nix [@dolstra_etall_2004], a functional package manager designed to make software installation deterministic, and {rix} [@rodrigues_baumann_2025], an R interface that allows researchers to use Nix without needing deep knowledge of its underlying language or infrastructure. Our objective is not to introduce a specific workflow orchestration system or to prescribe a particular analytic structure. Instead, we aim to show how Nix and {rix} can establish a stable, cross-platform environment within which any analysis—whether organized through simple, documented script sequences using `source()` or through more formal orchestration tools—can be executed reliably.

We illustrate these ideas through a reproducible simulation study conducted in R ~~via RStudio~~ \[**Do we need to show it via Rstudio? In fact there is nothing rstudio specific here. Maybe we show how you set up Rstudio/Positron/Vs code IDEs in Rix?\]**, culminating in an automated APA-formatted manuscript generated with apaquarto [@schneider_2024]. Although the example centers on R because of its prominence in psychological methodology, the principles underlying environment reproducibility apply equally to other languages, including Python and Julia, and to development environments such as VS Code, Emacs, or Positron. Later in the article, we briefly comment on {rixpress}, which extends Nix-based reproducibility to workflows requiring more sophisticated coordination across languages. Unlike {targets}, which is limited to R-based workflows, {rixpress} is designed for polyglot pipelines. This distinction is conceptually relevant, but workflow orchestration is not the focus of the present tutorial, which assumes a basic, documented execution order for scripts. Throughout, our emphasis remains squarely on the reproducibility of computational environments as the essential basis for transparent, reliable, and durable scientific workflows.

# Nix and {rix}: A Comprehensive Solution

\[**This kind of comes on very abruptly**\]. Nix is a package manager. That is, a system for installing and managing software. Unlike familiar tools such as `install.packages()` in R or `apt-get` on Linux, Nix addresses all four pillars of environment management—language versions, package versions, system dependencies, and cross-platform portability—through a fundamentally different approach [@rodrigues_baumann_2025]. Traditional package managers modify shared system directories, making installations depend on the existing state of the machine. Nix instead treats each environment as a fully specified, isolated configuration.

How about:

**\[Modern reproducible workflows must ensure that analyses yield identical results regardless of where—and when—they are run. Standard package managers fall short here: they install software into global system directories, inherit machine-specific quirks, and often lack precise version control. Nix directly addresses these limitations. Nix is a package manager, but one built around declarative, isolated environments rather than ad hoc system-level installations. Unlike familiar tools such as `install.packages()` in R or `apt-get` on Linux, Nix handles all four pillars of environment management—language versions, package versions, system dependencies, and cross-platform consistency—using a fundamentally different model [@rodrigues_baumann_2025]. Rather than modifying shared directories, Nix builds each environment as an explicit, self-contained specification.\]**

**\[Beyond traditional package management, Nix provides advantages relative to tools that many psychologists already use. For example, renv can lock R packages to specific versions, but it cannot manage system libraries (e.g., libcurl, libxml), compilers, Python dependencies, or OS-level configuration. As a result, renv environments may still fail to reproduce analyses on machines with different operating systems or different versions of system libraries. Docker, by contrast, captures the entire operating system and therefore achieves strong reproducibility, but at the cost of heavy, opaque images that are difficult to inspect and slow to build. Docker also lacks built-in mechanisms for expressing environments declaratively: users must manually manage Dockerfiles and ensure version consistency.\]**

**\[Nix effectively bridges these two approaches. Like renv, it provides transparent, language-level package version control; like Docker, it guarantees fully reproducible system environments. But Nix does so *without* requiring full OS images: environments are lightweight, composable, and defined by a single declarative file. This combination—precise version locking, complete control over system dependencies, and portable, declarative specifications—makes Nix particularly well suited for computational psychology workflows, especially those involving simulation code, R and Python interoperability, and long-term reproducibility of manuscripts\]**

\[maybe a bit more about nix\]

\[**Maybe compare Nix to renv and Docker to highlight what nix gives us**\]

## Core Principles

Rather than installing software into global directories (e.g., `/usr/lib`), Nix places every package in its own directory under `/nix/store`. Each package path contains a cryptographic hash representing its precise inputs—source code, dependencies, and build instructions. Because these paths are content-addressed, multiple versions of the same software can coexist without conflict. A researcher can, for example, maintain projects requiring R 4.1.0 and R 4.3.3 side by side, or use different package versions across analyses, switching between them seamlessly [@rodrigues_baumann_2025].

The Nix ecosystem is built around nixpkgs, a version-controlled repository comprising more than 120,000 packages, including nearly all of CRAN and Bioconductor. By pinning a specific commit or date, researchers freeze the entire software stack—R itself, R packages, and all system libraries—at that point in time. This eliminates the system-dependency problems that tools like renv cannot address [@rodrigues_baumann_2025].

This architecture also ensures stability over time. Large-scale empirical work rebuilding over 700,000 packages from historical nixpkgs snapshots shows rebuildability rates above 99% and bit-for-bit reproducibility between 69–91%, demonstrating strong protection against temporal drift. Combined with binary caches, which often allow environments to materialize in seconds, Nix becomes practical for interactive research workflows [@rodrigues_baumann_2025].

## The {rix} Package: R Interface to Nix

Nix expressions are written in a dedicated functional language unfamiliar to most researchers. The {rix} package removes this barrier by providing an R-native interface. A single call to `rix()` generates complete Nix configurations from standard R syntax, specifying R versions, CRAN packages, system libraries, and even Python or Julia components when required. Users never need to read or write Nix code directly, as {rix} performs the translation automatically [@rodrigues_baumann_2025].

A key feature of {rix} is its integration with rstats-on-nix, a community-maintained fork offering daily CRAN snapshots and weekly tested environments on Linux and macOS. Researchers can request, for example, `rix(date = "2024-12-14")` to obtain a validated and reproducible environment without manually assessing compatibility. After the configuration is generated, `nix_build()` instantiates the environment, and binary caches typically allow this to complete within seconds [@rodrigues_baumann_2025].

Although Nix is capable of replacing tools like Docker for isolation or {renv} for package management, it does not require an all-or-nothing transition. Researchers can adopt it gradually and use it alongside familiar tooling. For instance, by building Docker images with Nix, converting existing {renv} lockfiles, or running {targets} pipelines within a Nix-defined environment. This allows Nix to strengthen reproducibility while preserving established workflows. For projects requiring more sophisticated pipeline management, {rixpress} extends Nix’s guarantees to workflow orchestration, enabling step-level isolation across languages, though such capabilities lie beyond the present focus on environment reproducibility. We will come back to this after the tutorial.

# A Practical Example: Setting Up a Reproducible Simulation Study with {rix}

\[My idea – take it or leave it– would be to have a fake repository set up where it cant be reproduced (we can highlight errors etc\] and the a solution is to use rix and can highlight what packages are needed etc.\].

Before proceeding with the technical implementation and tutorial, we refer readers to Appendix, which outlines a common simulation study scenario[^1]. This will serve as a guiding example. Simulation studies in psychology typically structure code into multiple component files, each handling a distinct analytical phase. Our implementation follows this convention, organizing the workflow into five sequential files: data generation function (`01_data_generation.R`), statistical model specification (`02_models.R`), simulation execution (`03_run_simulation.R`), performance metric calculation (`04_performance_metrics.R`), and result visualization (`05_plots.R`). The simulation script (`03_run_simulation.R`) sources the data generation and model functions, executes the Monte Carlo replications, and saves results. The subsequent scripts read these saved results to compute performance metrics and generate visualizations. For convenience, we provide a master script (`06_run_all.R`) that loads all required packages and executes the complete workflow sequentially. Note that such sequential structures could benefit from explicit workflow orchestration tools and a clear documentation[^2].

[^1]: Note that the rationale, programming-related choices (e.g., package choices), and results should not be used for substantial interpretation. However, we do highlight useful information that are based on recommendations for simulation studies [@siepe_etall_2024; @morris_etall_2019; @white_etall_2024] (see Computational Details in Appendix).

[^2]: For instance, in this context, we use parallel processing which requires specifying the amount of cores to be used. This type of information should be mentioned.

\[Readers can find the files for these simulations here:\]

## Step I: Installing Nix and {rix}

It is possible to use {rix} to generate Nix expressions even without having Nix installed on your system \[Yes. But why? I think we go with download Nix and use Rix but you dont need to do this. This should be secondary\]. In practice, this means that you can write a configuration (e.g., a `default.nix` file) without using Nix directly, but you cannot build or enter the resulting environment unless Nix is installed [@rodrigues_baumann_2025]. Think of it like writing a recipe without needing a kitchen—{rix} helps you document exactly what ingredients are needed (e.g., which R version, which packages, which system dependencies), but you need Nix (the kitchen) to actually cook the meal.

\[The fact you dont need nix should be a footnote. I think it is helpful to install nix.\]

### Installing Nix

\[What if you have mac?\]

Installation procedures differ across systems, and we highly suggest readers to consult the {rix} documentation for more information[^3].

[^3]: See: <https://docs.ropensci.org/rix/articles/b2-setting-up-and-using-rix-on-macos.html> and <https://docs.ropensci.org/rix/articles/b1-setting-up-and-using-rix-on-linux-and-windows.html>

**Windows (via WSL2)**. On Windows, Nix runs inside the Windows Subsystem for Linux 2 (WSL2). To enable WSL2, run the following in PowerShell as an administrator: \small

::: callout-note
We should use lsting captions for all code.
:::

```         
wsl --install
```

\normalsize

After installing a Linux distribution (e.g., Ubuntu), it is recommended to activate `systemd`, which improves compatibility with Nix. In your WSL2 shell, edit `/etc/wsl.conf`: \small

``` bash
sudo -i
nano /etc/wsl.conf
```

\normalsize

Add: \small

```         
[boot]
systemd=true
```

\normalsize

Save the file, then shut down WSL from PowerShell: \small

``` powershell
wsl --shutdown
```

\normalsize

After shutting down WSL, launch your WSL2 Ubuntu environment again from the Start menu.

**Installing Nix (Linux and Windows)**[^4].Once your Linux or WSL2 environment is ready, install Nix using the Determinate Systems installer: \small

[^4]: Windows users who choose not to enable `systemd` may need to append `--init none`; see {rix} documentation highlighted above.

``` bash
curl --proto '=https' --tlsv1.2 -sSf \
  -L https://install.determinate.systems/nix | \
  sh -s -- install
```

\normalsize

After installation, set up the `rstats-on-nix` binary cache, which provides pre-built R packages and speeds up environment builds: \small

``` bash
nix-env -iA cachix -f https://cachix.org/api/v1/install
cachix use rstats-on-nix
```

\normalsize

Although {rix} includes a `setup_cachix()` helper, the {rix} documentation recommends configuring the cache with the `cachix` client, as this properly updates system-level files when needed.

**macOS**. On macOS, install Nix using the same Determinate Systems installer:

\small

``` bash
curl --proto '=https' --tlsv1.2 -sSf \
  -L https://install.determinate.systems/nix | \
  sh -s -- install
```

\normalsize

Then enable the `rstats-on-nix` binary cache:

\small

``` bash
nix-env -iA cachix -f https://cachix.org/api/v1/install
cachix use rstats-on-nix
```

\normalsize

## Installing {rix}

The method for installing {rix} depends on whether you already have R installed on your system. If you have R installed, you can install {rix} the usual way. For the CRAN version:

\small \[small normalsize is not doing anything\]

```{r}
#| lst-cap: Install {rix}
#| echo: true
#| eval: false

install.packages("rix") # CRAN

install.packages("rix", repos = c("https://ropensci.r-universe.dev")) # Developmental version


```

```         
install.packages("rix")
```

\normalsize

Once {rix} is installed, you can use it to generate `default.nix` files for your projects, which you then build with Nix. This latter part is explained in the next subsection (i.e., Specifying the Computational Environment).

However, note that if you have installed Nix but do not yet have R on your system, or if you prefer to work entirely within the Nix ecosystem from the start, you can obtain both R and {rix} directly through Nix without installing R through the "traditional" means. The simplest approach is to create a temporary Nix shell that includes both R and {rix} by running this command in your terminal: \small

``` bash
nix-shell --expr "$(curl -sl 
  https://raw.githubusercontent.com/ropensci/rix/main/inst/extdata/default.nix)"
```

\normalsize

This creates an ephemeral environment where R and the development version of {rix} are immediately available. You can then start R within this shell, use {rix} to generate your project's `default.nix` file, and exit. Alternatively, if you prefer the stable CRAN version of {rix}, you can create a temporary shell with \small

``` bash
nix-shell -p R rPackages.rix
```

\normalsize

Note that the {rix} documentation recommends managing R versions exclusively through Nix rather than mixing system-installed R with Nix-managed environments for optimal reproducibility, though both approaches are supported (see the following {rix} documentation: <https://docs.ropensci.org/rix/articles/z-advanced-topic-walkthrough-project.html>).

## Step II: Specifying the Computational Environment

The initial step in establishing a reproducible environment is to create a script that will generate the environment specification. We recommend creating a file named `generate_env.R` (or similar) in the project directory. This script will use the `rix()` function from the {rix} package to produce a `default.nix` file—a declarative specification that precisely defines all software dependencies required for the project.

For our simulation study, we implement the following environment specification, which can be found on the GitHub repository as a file named `generate_env.R`:

\small

\[Are we using marignaleffects?Where?\]

\[We should cite the packages used in footnote. I included html fromegrateful package\].

```{r}
#| eval: false
#| echo: true
#library(rix)
rix(
  date = "2025-08-25",
  r_pkgs = c("rix", "quarto", "knitr", 
             "marginaleffects", "simhelpers", "ggplot2",
             "doParallel", "doRNG", "cowplot",
             "dplyr"),
  system_pkgs = c("quarto"),
  ide = "rstudio",
  project_path = ".",
  overwrite = TRUE
)
```

\normalsize

### The Environment Generation Script[^5]

[^5]: For an overarching information on the function `rix()`, we suggest the following {rix} documentation: <https://docs.ropensci.org/rix/articles/c-using-rix-to-build-project-specific-environments.html>

The `rix()` function constructs this specification through a series of parameters that collectively describe the computational environment. Each parameter serves a distinct purpose in defining the environment's characteristics.

\[Maybe put line numbers for each part of rix for readers?\]

#### **Specifying the R version \[lines X\]**

Researchers must first determine which version of R to use. This can be accomplished in two ways: The `r_ver` parameter accepts an exact version string (e.g., "4.3.3") or special designations such as "latest-upstream" for the most recent stable release. Alternatively, the `date` parameter specifies a particular date (e.g., "2024-11-15"), which ensures that R and all packages correspond to the versions available on that date. The date-based approach is generally preferable for reproducibility, as it captures a complete snapshot of the R ecosystem at a single point in time. For this tutorial, we use the `date` parameter to ensure temporal consistency across all software components [@rodrigues_baumann_2025] (see {rix} documentation for more: <https://docs.ropensci.org/rix/articles/d2-installing-system-tools-and-texlive-packages-in-a-nix-environment.html>).

#### **Declaring R package dependencies**

The `r_pkgs` parameter accepts a character vector listing all required R packages by their CRAN names. These packages will be installed from the version repository corresponding to the specified date or R version. It is important to list all packages that the analysis will load directly; dependencies of these packages are automatically resolved by Nix. For packages requiring specific versions not corresponding to the chosen date, researchers can specify exact versions using the syntax `"packagename@version"` (e.g., `"ggplot2@2.2.1"`). For packages available only on GitHub or other Git repositories, the `git_pkgs` parameter accepts a list structure containing repository URLs and specific commit hashes. This ensures that exact development versions are obtained, which is particularly valuable when collaborating with package developers or requiring unreleased features [@rodrigues_baumann_2025] (see {rix} documentation for more: <https://docs.ropensci.org/rix/articles/d2-installing-system-tools-and-texlive-packages-in-a-nix-environment.html>).

**Including system-level dependencies.** Many R-based workflows require tools beyond R packages. The `system_pkgs` parameter specifies system-level software such as Quarto for document generation, Git for version control, or Pandoc for document conversion. The `tex_pkgs` parameter, similarly, lists LaTeX packages needed for PDF compilation. These can be added as needed for specific document formatting requirements. Critically, we include Quarto as a system package because this tutorial demonstrates full computational reproducibility—not merely of the simulation code, but of the complete manuscript itself. Our manuscript uses the `apaquarto` extension for APA formatting, stored in the project's `_extensions/` directory. Quarto extensions do not require explicit declaration in the Nix specification; when the `_extensions/` folder is committed to the repository, users building the environment automatically have access to these extensions [@rodrigues_baumann_2025] (see {rix} documentation for more: <https://docs.ropensci.org/rix/articles/d2-installing-system-tools-and-texlive-packages-in-a-nix-environment.html>).

#### **Multi-language environment support**

While this tutorial focuses on R, researchers working across multiple programming languages can include Python or Julia in their environments. The `py_conf` parameter accepts a list specifying a Python version and required packages (e.g., `py_conf = list(py_version = "3.12", py_pkgs = c("polars", "pandas"))`). Similarly, `jl_conf` enables Julia package installation. This capability is particularly useful for projects requiring statistical computing in R alongside machine learning pipelines in Python or numerical optimization in Julia [@rodrigues_baumann_2025] (see {rix} documentation for more: <https://docs.ropensci.org/rix/articles/d1-installing-r-packages-in-a-nix-environment.html>).

#### **Configuring the development environment**

The `ide` parameter determines whether an integrated development environment should be included. Setting `ide = "rstudio"` installs a project-specific version of RStudio within the Nix environment. Note that on macOS, RStudio is only available through Nix for R versions 4.4.3 or later (or dates after 2025-02-28); for earlier versions, alternative editors must be used. Other supported IDEs include Positron (`ide = "positron"`), Visual Studio Code (`ide = "code"`), and command-line tools such as Radian (`ide = "radian"`). Each IDE installed via Nix is project-specific and will not interfere with system-wide installations. Researchers preferring to use an already-installed editor can set `ide = "none"` and configure their editor to interact with Nix shells [@rodrigues_baumann_2025] (see {rix} documentation for more: <https://docs.ropensci.org/rix/articles/e-configuring-ide.html>).

#### **Setting file output parameters**

The `project_path` parameter indicates where the `default.nix` file should be written ("." denotes the current directory), while `overwrite` controls whether an existing file should be replaced. Setting `print = TRUE` displays the generated specification in the console for immediate verification [@rodrigues_baumann_2025].

### Generating the Environment Specification

Executing this script, either by running from the terminal `Rscript generate_env.R`, sourcing it from within R using `source("generate_env.R")`, \*\*or running the `rix::rix()` function above\*\* generates the `default.nix` file in the project directory. This file serves as the formal, machine-readable specification of the computational environment. Importantly, `rix()` automatically invokes `rix_init()`, which creates a project-specific `.Rprofile` file that prevents package library conflicts and disables `install.packages()` to maintain environment integrity.

## Step III: Building and Using the Reproducible Environment

Once the `default.nix` file has been generated, the next step is to build the environment and use it to reproduce either the simulation analyses or the complete manuscript. This section demonstrates both workflows.

\[what is in the default.nix script\]?

### Building the Environment

From the terminal, navigate to the project directory containing the `default.nix` file and execute:

``` bash
nix-build
```

This command builds the environment according to the specification. The first execution will download and install all required packages, which may take a few minutes depending on network speed and system resources. Subsequent builds use cached packages and complete in seconds. Upon successful completion, a symbolic link named `result` appears in the project directory, pointing to the constructed environment in the Nix store.

To activate the environment, run:

``` bash
nix-shell
```

This command drops the user into a shell where all specified packages and tools are available. The shell prompt typically changes to indicate that a Nix environment is active (e.g., `[nix-shell:~/project]$`). If RStudio was specified via `ide = "rstudio"`, it can be launched from within this shell by typing `rstudio`, ensuring it uses the project-specific R installation and package library. \[To make sure version of R \> 4.2 is used\]

### Reproducing the Simulation

\[We need more information about the simulation. Readers should not have to go to Appendix to learn about what we are doing. We should descibe what \]

As described before, our example contains multiple scripts. For streamlined execution, we provide a master script (`06_run_all.R`) that runs all simulation:

\small

::: callout-note
Sep out packages from code. This is a sep step.
:::

```{r}
# required packages
library(marginaleffects); library(simhelpers)
library(doParallel); library(doRNG); library(ggplot2)
```

\[Maybe have each of these steps in sep chunks with explanation of what they do under each and corresponding plots?\]

```{r}
#| lst-lavel: rix-sim
#| lst-cap: running the simulation
#| eval: false
#| echo: true

# step 1: run simulation (sources 01 and 02)
source("03_run_simulation.R")

# step 2: calculate performance metrics
source("04_performance_metrics.R")

# step 3: generate plots
source("05_plots.R")
```

\normalsize

Thus, to reproduce the simulation from within the Nix shell:

``` bash
Rscript 06_run_all.R
```

This executes the complete simulation sequentially: first running the Monte Carlo replications which save results to `sim_results.rds`, then computing performance metrics and saving the summary table to `performance_summary.rds`, and finally generating all figures. Alternatively, individual scripts can be executed separately. The key advantage of executing within `nix-shell` is that all dependencies—R version, packages, and system tools—match exactly those specified in `default.nix`.

### Reproducing the Complete Manuscript[^6]

[^6]: See the {rix} documentation for more: https://docs.ropensci.org/rix/articles/z-advanced-topic-building-an-environment-for-literate-programming.html.

Beyond reproducing computational results, the Nix environment enables full manuscript reproducibility. The manuscript source file (`article.qmd`) combines narrative text, executable code chunks, and references to simulation outputs. In our specific case, we do not integrate the simulation run itself in the manuscript. \[but you can\]. We just load the obtained performance measures and integrate the code chunks that produce the plots (see Figure 1)\[cross ref figures and tables\]. To render the manuscript: \[You can if we use rixpress\]

``` bash
quarto render article.qmd 
```

This command executes all code chunks in the manuscript, incorporates results and figures, and generates a formatted PDF following APA style guidelines via the apaquarto extension [@schneider_2024]. This extension is saved in the proejct repo already.

To download this extension for your own work you can install the extension by using the terminal:

```{base}
quarto use template wjschne/apaquarto
```

or in the console:

```{bash}

quarto::quarto_use_template("wjschne/apaquarto")

```

The final document (.pdf) is saved directly in the project folder. Because Quarto is installed as a system-level package in our Nix specification, the rendering occurs entirely within a fully reproducible environment, ensuring consistent output across machines regardless of local software configurations. If desired, the manuscript can also be reproduced interactively by opening the project folder in the user’s preferred IDE and running the code chunks directly.

```{r}
#| label: load-results
#| echo: false
#| message: false

summary_table <- readRDS("Simulation_Scripts/performance_summary.rds")

```

```{r}
#| label: fig-performance
#| fig-cap: "Performance of ACE estimator across sample sizes and confounding severity. Panel A shows relative bias, Panel B shows relative RMSE, Panel C shows coverage probability of 95% confidence intervals (dashed line at nominal 0.95 level), and Panel D shows average confidence interval width. Results demonstrate that model misspecification induces systematic bias that persists across sample sizes, while increasing sample size improves precision but not accuracy under misspecification."
#| fig-width: 10
#| fig-height: 8
#| echo: false
#| warning: false

# aanel A: Relative Bias
p_rel_bias <- ggplot(summary_table,
                     aes(x = n, y = rel_bias,
                         color = confound_label, group = confound_label)) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray50") +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Relative Bias",
       color = "Confounding\nnon-linearity",
       title = "A. Relative Bias") +
  theme_minimal() +
  theme(legend.position = "none")

# panel B: Relative RMSE
p_rel_rmse <- ggplot(summary_table,
                     aes(x = n, y = rel_rmse,
                         color = confound_label, group = confound_label)) +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Relative RMSE",
       color = "Confounding\nnon-linearity",
       title = "B. Relative RMSE") +
  theme_minimal() +
  theme(legend.position = "none")

# panel C: Coverage
p_coverage <- ggplot(summary_table,
                     aes(x = n, y = coverage,
                         color = confound_label, group = confound_label)) +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "gray50") +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Coverage of 95% CI",
       color = "Confounding\nnon-linearity",
       title = "C. Coverage Probability") +
  coord_cartesian(ylim = c(0, 1)) +
  theme_minimal() +
  theme(legend.position = "none")

# panel D: CI Width
p_width <- ggplot(summary_table,
                  aes(x = n, y = width,
                      color = confound_label, group = confound_label)) +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Average CI Width",
       color = "Confounding\nnon-linearity",
       title = "D. Confidence Interval Width") +
  theme_minimal() +
  theme(legend.position = "none")

legend <- get_legend(
  p_rel_bias + theme(legend.position = "right")
)

# 2x2 grid 
plot_grid(
  plot_grid(p_rel_bias, p_rel_rmse, p_coverage, p_width, 
            ncol = 2, nrow = 2),
  legend,
  rel_widths = c(3, 0.4)
)
```

```{r}
#| label: tbl-results
#| tbl-cap: "Performance metrics for ACE estimator across simulation conditions"
#| echo: false

results_display <- summary_table %>%
  select(n, confound_label, rel_bias, rel_rmse, coverage, width) %>%
  mutate(
    `Sample Size` = n,
    `Confounding` = confound_label,
    `Relative Bias` = sprintf("%.3f", rel_bias),
    `Relative RMSE` = sprintf("%.3f", rel_rmse),
    `Coverage` = sprintf("%.3f", coverage),
    `CI Width` = sprintf("%.3f", width)
  ) %>%
  select(`Sample Size`, `Confounding`, `Relative Bias`, 
         `Relative RMSE`, `Coverage`, `CI Width`)

kable(results_display, align = "lccccc", row.names = FALSE)
```

# Additional Considerations for Advanced Workflows

## Workflow Orchestration: {targets} and {rixpress}

Complex simulation studies often benefit from workflow management systems that track dependencies between computational steps, cache intermediate results, and enable selective re-execution when inputs change. Two complementary approaches exist within the Nix ecosystem: using {targets} inside a Nix environment, or using {rixpress} to leverage Nix itself as the build automation tool.

**Using {targets} within Nix.** As mentioned, the {targets} package [@landau_2021] provides workflow orchestration for R-based projects. This combination ensures both computational reproducibility (via Nix controlling the environment) and computational efficiency (via targets' intelligent caching). To integrate {targets} with Nix, simply include "targets" in the `r_pkgs` parameter of `rix()`, and execute the pipeline within `nix-shell` using `Rscript -e 'targets::tar_make()'`. The {targets} metadata directory (`_targets/`) should be excluded from version control while the `_targets.R` configuration file should be committed alongside `default.nix` [@rodrigues_baumann_2025]. This approach is ideal for projects that remain within the R ecosystem and do not require different computational environments for different pipeline steps (see {rix} documentation: <https://docs.ropensci.org/rix/articles/z-advanced-topic-reproducible-analytical-pipelines-with-nix.html>).

**Using {rixpress} for polyglot pipelines.** The {rixpress} package [@rixpress], a sister package to {rix}, uses Nix itself as the build automation tool rather than operating within a Nix environment. Each pipeline step becomes a Nix derivation, providing hermetic builds with sandboxed execution and content-addressable caching. The key advantage of {rixpress} emerges in multi-language workflows: different steps can execute in different Nix-defined environments (e.g., one step using R 4.2.0 with specific packages, another using Python 3.12 with machine learning libraries, another using Julia for numerical optimization). The package interface, inspired by {targets}, uses functions like `rxp_r()`, `rxp_py()`, and `rxp_jl()` to define pipeline steps, with automatic serialization handling data transfer between languages. Objects are stored in the Nix store and can be inspected interactively using helper functions like `rxp_read()` and `rxp_load()` (see {rixpress} documentation: <https://docs.ropensci.org/rixpress/articles/intro-concepts.html>).

## Converting Existing {renv} Projects

Many researchers have existing projects using {renv} for package management. The `renv2nix()` function facilitates migration by reading an `renv.lock` file and generating an equivalent Nix specification. This conversion is particularly valuable for projects where {renv} encountered system dependency issues or where stricter reproducibility guarantees are desired. However, researchers should note that while {renv} snapshots R package versions, Nix additionally pins system libraries and compilers, potentially exposing previously hidden dependencies on system configuration [@rodrigues_baumann_2025] (see {rix} documentation: <https://docs.ropensci.org/rix/articles/f-renv2nix.html>).

## Containerization with Docker

Institutions with existing Docker-based infrastructure may wish to combine Nix with containers. While this might seem redundant—both technologies provide isolation—the combination offers complementary benefits: Nix ensures bit-reproducible builds across systems, while Docker provides a familiar deployment mechanism for non-Nix-aware computing environments. The approach is to use Nix as the base layer within a Docker container [@rodrigues_baumann_2025]. This strategy is particularly relevant, for example, for projects requiring deployment to cloud computing platforms or high-performance computing clusters where Docker is the standard containerization technology (see {rix} documentation: <https://docs.ropensci.org/rix/articles/z-advanced-topic-using-nix-inside-docker.html>\]).

## Example (extremely brief) with Python (?)

\[I do not think this is necessary. We can include online supplement.\]

\[...\]

# Discussion

\[...\]

{{< pagebreak >}}

# References

::: {#refs}
:::

{{< include appendix_a.qmd >}}