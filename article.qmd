---
title: "Why Risk it, When You Can {rix} it: A Tutorial for Reproducibility Focused on Simulation Studies"
shorttitle: "Reproducibility with rix"
author:
  - name: Felipe Fontana Vieira
    corresponding: true
    email: felipe.fontanavieira@ugent.be
    affiliations:
      - name: Ghent University 
        department: Department of Data Analysis 
  - name: Jason Geller
    affiliations:
      - name: Boston College
        department: Department of Psychology and Neuroscience
  - name: Bruno Rodrigues
    affiliations:
      - name: Ministry of Research and Higher Education, Luxembourg
        department: Statistics and Data Strategy Departments
abstract: |
  Reproducibility remains limited in psychology, in part because
  reproducibility exists on a spectrum -- from sharing isolated code fragments 
  to providing fully executable pipelines that ensure identical results.
  This article demonstrates how Nix and the {rix} R package provide a 
  comprehensive solution for achieving full computational reproducibility in 
  simulation studies.
keywords: [reproducibility, Nix, simulation studies, R, computational methods]
word-count: true
authornote: |
  Author contributions: [Add contributions]
  
  Correspondence concerning this article should be addressed to [Name], [Address]. 
  Email: [email]
format:
  apaquarto-pdf:
    documentmode: man
    keep-tex: true
    include-in-header:
      text: |
        \raggedbottom
  #apaquarto-html: default
  
bibliography: references.bib
---

```{r}
#| label: load-packages
#| echo: false
#| message: false

library(ggplot2)
library(knitr)
library(cowplot)
library(dplyr)

```

Reproducibility remains limited in psychological science, in part because reproducibility operates along a continuum rather than as a binary property [@peng_2011]. At the lower end of this continuum, researchers share only their manuscript. As we progress along this spectrum, authors may share isolated code fragments, complete analysis scripts, or structured data repositories. At the higher end, researchers provide a fully specified *computational environment*—the complete software stack (programming language version, packages, system dependencies, operating system) necessary to regenerate identical results from raw data through final manuscript. Achieving comprehensive reproducibility requires satisfying multiple distinct requirements simultaneously. Following @rodrigues_2023, fully reproducible research should provide: (1) source code that is available and documented, (2) dependencies that are easy to find and install, (3) implementation using open-source programming languages, (4) execution on open-source operating systems, and (5) accessible data and outputs. Indeed, other articles emphasized some or all of these requirements [@peikert_brandmaier_2021; @ziemann_etall_2023; @wiebels_moreau_2021; @epskamp_2019; @siepe_etall_2024].

Although awareness of reproducibility has increased—supported by journal incentives such as open-science badges [@kidwell_etall_2016], R packages [@ushey_2024; @simonsohn_2020; @peikert_brandmaier_2021; @landau_2021], and the growing methodological literature (see references above)—recent empirical assessments reveal that simulation studies in psychology particularly struggle to meet these standards. @siepe_etall_2024 found that nearly two-thirds of simulation studies fail to provide any accompanying code, and among those that do, comprehensive documentation of computational environments is exceptionally rare. This gap is especially concerning for methodological research: simulation studies form some of the empirical foundation for statistical recommendations, yet their limited reproducibility undermines confidence in those recommendations [@white_etall_2024]. Notably, while code availability has improved through platforms like GitHub and the Open Science Framework (OSF), dependency management (i.e., controlling and documenting all the software components that your code depends on to run correctly.) remains severely underdeveloped. Thus, even when code is shared, failing to specify or control the surrounding software environment undermines reproducibility: analyses may succeed on one machine yet fail or yield different numerical results on another [@baker_etall_2024; @hodges_etall_2023; @glatard_etall_2015].

Several structural factors contribute to these persistent limitations. The reproducibility literature documents various tools addressing distinct reproducibility layers, yet this fragmented landscape creates a demanding situation where researchers must learn and coordinate multiple specialized systems, each targeting only specific parts of the reproducibility continuum. Package-level managers like {renv} [@ushey_2024], {groundhog} [@simonsohn_2020], and {rang} [@chan_2023] stabilize R package versions but cannot manage R itself or system dependencies. Documentation tools like sessionInfo() record environments but offer no reconstruction mechanism. Workflow orchestration tools such as {targets} [@landau_2021] and Make [@feldman_1979] manage computational pipelines but assume stable environments. Containerization through Docker and the Rocker project [@boettiger_2015; @boettiger_eddelbuettel_2017] provides the most comprehensive solution—packaging operating system, system libraries, R version, and packages together—but demands Linux administration knowledge that many researchers lack [@wiebels_moreau_2021] and, as @malka2024 demonstrate, suffers from temporal irreproducibility where identical specifications produce different outputs over time. Moreover, contemporary research in psychology increasingly incorporates multiple programming languages (Python, Julia) alongside system-level tools (Quarto), requiring coordination across software ecosystems that existing solutions provide limited guidance for managing cohesively. Consequently, researchers face a choice between partial solutions that are accessible but incomplete, or comprehensive solutions that are powerful but technically demanding.

Therefore, in this article, we introduce Nix [@dolstra_etall_2004], a functional package manager that addresses *computational environment management* comprehensively^[We again highlight that this tutorial focuses specifically on computational environment management, thus ensuring that four critical components work reliably: (1) the correct version of the programming language is installed (e.g., R 4.3.3 versus 4.4.0), (2) the required versions of packages are installed, (3) necessary system dependencies are available, and (4) all of these can be installed across different hardware and operating systems. While other requirements—such as code availability through version control (e.g., Git) and workflow orchestration—remain important (in fact, we use Git for this project and highlight {targets} as well as {rixpress} later on), environment management forms the foundation upon which other reproducibility practices depend: without a stable software stack, even perfectly documented and orchestrated workflows may fail to execute or produce different results across systems.], and {rix} [@rodrigues_baumann_2025], an R interface that makes Nix accessible to researchers. Our tutorial demonstrates {rix} through a concrete scenario: creating a fully reproducible simulation study using R through RStudio, culminating in automated APA-formatted manuscript generation via apaquarto [@schneider_2024]. This step-by-step example shows how to establish stable computational environments from initial project setup through statistical analysis, visualization, and final manuscript preparation. While we focus on R and RStudio as our primary use case—reflecting the dominant tools in psychological simulation research—the same principles apply to other programming languages (e.g., Python, Julia) and development environments (e.g., VS Code, Emacs, Positron), which we briefly illustrate. Moreover, as mentioned, environment management remains our central focus, but we also briefly discuss how {rixpress} can extend Nix-based approaches to workflow orchestration, illustrating how these tools complement existing frameworks like {targets} when projects require more sophisticated pipeline management.

This article proceeds as follows. We begin by introducing Nix and {rix}, explaining how this unified framework can replace and extend the functionality of multiple specialized tools for environment management. We then provide a complete tutorial demonstrating how to use {rix} to create a reproducible simulation study, from initial setup through to generating an APA-formatted manuscript with integrated analyses, performance metrics, plots, and tables.

# Nix and {rix}: A Comprehensive Solution

Nix is a package manager, meaning a software that installs and manages other software on your computer. However, unlike familiar package managers such as `install.packages()` in R or `apt-get` on Linux, Nix addresses all four environment management components—language versions, package versions, system dependencies, and cross-platform compatibility—through a fundamentally different approach [@rodrigues_baumann_2025]. Traditional package managers install software by modifying shared system directories, meaning the outcome depends on what's already installed and when you run the installation. Nix instead treats each software environment as a self-contained specification.

## Core Principles

Unlike traditional package managers that install software into shared system directories (like `/usr/lib`), Nix installs every package in isolation within `/nix/store`. Each package receives a unique directory path that includes a cryptographic hash—essentially a fingerprint derived from its source code, dependencies, and build settings. Because these paths are content-based rather than location-based, multiple versions of the same package coexist without conflict. Researchers can maintain separate projects requiring R 4.1.0 and R 4.3.3 simultaneously, or use different versions of the same packages across different analyses, switching between them instantaneously [@rodrigues_baumann_2025].

The Nix ecosystem centers on nixpkgs, a version-controlled repository containing over 120,000 packages, including nearly all of CRAN and Bioconductor. By specifying a particular date or commit hash from nixpkgs, researchers freeze their entire software stack (i.e., R version, packages, and system dependencies) at that point in time. This solves the system dependency problem that plagues tools like renv: when specifying the sf package, Nix automatically installs and configures the required GDAL, GEOS, and PROJ libraries with compatible versions, eliminating manual platform-specific installation procedures [@rodrigues_baumann_2025].

This approach ensures temporal stability. Large-scale empirical validation by @malka_etall_2025—rebuilding over 700,000 packages from 2017-2023—found rebuildability rates exceeding 99% and bit-for-bit reproducibility between 69-91%, directly addressing Docker's temporal drift problem. Binary caches typically complete environment builds in seconds, making Nix practical for interactive research workflows.

## The {rix} Package: R Interface to Nix

Nix configurations are written in the Nix expression language, a domain-specific functional programming language unfamiliar to most researchers. The {rix} package eliminates this learning barrier by providing an R-native interface. A single `rix()` function call generates complete Nix configurations from familiar R syntax, specifying R versions, CRAN packages, system dependencies, and even Python or Julia components when needed. Researchers never need to write or understand Nix code directly as {rix} handles the translation automatically.

Crucially, {rix} leverages rstats-on-nix, a community-maintained fork providing daily CRAN snapshots and weekly tested configurations on Linux and macOS. Researchers can specify `rix(date = "2024-12-14")` to obtain validated environments rather than manually testing compatibility. After generating the configuration, researchers use `nix_build()` to instantiate the environment. Binary packages cached through Cachix typically complete builds in seconds rather than requiring compilation from source.

Importantly, Nix may also complement existing tools rather than replacing them: researchers can use Nix within Docker for deployment, convert renv lockfiles to Nix expressions for gradual migration, or continue using targets for workflow management atop Nix-managed environments. For projects requiring sophisticated pipeline management beyond simple sequential scripts, {rixpress} [@rodrigues_rixpress_2025] extends Nix-based environment control to workflow orchestration, though such extensions remain secondary to our present focus on environment reproducibility.

# A Practical Example: Setting Up a Reproducible Simulation Study with {rix}

Before proceeding with the technical implementation, we refer readers to Appendix A, which outlines a common simulation study scenario^[Note that the rationale, programming-related choices (e.g., package choices), and results should not be used for substantial interpretation. However, we do highlight useful information that are based on recommendations for simulation studies [@siepe_etall_2024; @morris_etall_2019; @white_etall_2024] (see Computational Details in Appendix A).]. This will serve as a guiding example. Simulation studies in psychology typically structure code into multiple component files, each handling a distinct analytical phase. Our implementation follows this convention, organizing the workflow into five sequential files: data generation function (`01_data_generation.R`), statistical model specification (`02_models.R`), simulation execution (`03_run_simulation.R`), performance metric calculation (`04_performance_metrics.R`), and result visualization (`05_plots.R`). The simulation script (`03_run_simulation.R`) sources the data generation and model functions, executes the Monte Carlo replications, and saves results. The subsequent scripts read these saved results to compute performance metrics and generate visualizations. For convenience, we provide a master script (`06_run_all.R`) that loads all required packages and executes the complete workflow sequentially. Note that such sequential structures could benefit from explicit workflow orchestration tools like {targets} (Landau, 2021) and a clear documentation^[For instance, in this context, we use parallel processing which requires specifying the amount of cores to be used. This type of information should be mentioned.].

## Step I: Installing Nix and {rix}

It is possible to use {rix} to generate Nix expressions even without having Nix installed on your system. Think of it like writing a recipe without needing a kitchen—{rix} helps you document exactly what ingredients are needed (e.g., which R version, which packages, which system dependencies), but you need Nix (the kitchen) to actually cook the meal. This separation means you could write the configuration for a reproducible environment on one machine and build it on another. However, to actually build and use these environments, you need Nix installed.

### Installing Nix

Installation procedures vary by platform:

**Linux:** Open a terminal and run the Determinate Systems installer:
\small
```bash
curl --proto '=https' --tlsv1.2 -sSf \
    -L https://install.determinate.systems/nix | \
     sh -s -- install
```
\normalsize

**Windows:** First, ensure WSL2 is installed. Run as administrator in PowerShell:
\small
```powershell
wsl --install
```
\normalsize

Then activate systemd in your WSL2 Ubuntu environment by editing `/etc/wsl.conf`:
\small
```bash
sudo nano /etc/wsl.conf
```
\normalsize

Add these lines:
\small
```
[boot]
systemd=true
```
\normalsize

Save and restart WSL with `wsl --shutdown` in PowerShell. Finally, install Nix using the same Linux command above.

**macOS:** Open a terminal and run:
\small
```bash
curl --proto '=https' --tlsv1.2 -sSf \
    -L https://install.determinate.systems/nix | \
     sh -s -- install
```
\normalsize

For all the above platforms, after installation, configure the `rstats-on-nix` binary cache to speed up environment builds:
\small
```bash
nix-env -iA cachix -f https://cachix.org/api/v1/install
cachix use rstats-on-nix
```
\normalsize

We highlight suggest consulting the {rix} documentation for a more comprehensive platform-specific instructions, troubleshooting guidance, and additional configuration details: <https://docs.ropensci.org/rix/articles/b1-setting-up-and-using-rix-on-linux-and-windows.html> (Linux/Windows) and <https://docs.ropensci.org/rix/articles/b2-setting-up-and-using-rix-on-macos.html> (macOS).

## Installing {rix}

The method for installing {rix} depends on whether you already have R installed on your system. If you have R installed, you can install {rix} the usual way. For the CRAN version:
\small
```
install.packages("rix")
```
\normalsize

While for the development version:
\small
```
install.packages("rix", repos = c("https://ropensci.r-universe.dev"))
```
\normalsize

Once {rix} is installed, you can use it to generate `default.nix` files for your projects, which you then build with Nix. This latter part is explained in the next subsection (i.e., Specifying the Computational Environment). This tutorial will be focused on this scenario.

However, note that if you have installed Nix but do not yet have R on your system, or if you prefer to work entirely within the Nix ecosystem from the start, you can obtain both R and {rix} directly through Nix without installing R through the "traditional" means. The simplest approach is to create a temporary Nix shell that includes both R and {rix} by running this command in your terminal:
\small
```bash
nix-shell --expr "$(curl -sl 
  https://raw.githubusercontent.com/ropensci/rix/main/inst/extdata/default.nix)"
```
\normalsize

This creates an ephemeral environment where R and the development version of {rix} are immediately available. You can then start R within this shell, use {rix} to generate your project's `default.nix` file, and exit. Alternatively, if you prefer the stable CRAN version of {rix}, you can create a temporary shell with 
\small
```bash
nix-shell -p R rPackages.rix
```
\normalsize

Note that the {rix} documentation recommends managing R versions exclusively through Nix rather than mixing system-installed R with Nix-managed environments for optimal reproducibility, though both approaches are supported.

## Step II: Specifying the Computational Environment

The initial step in establishing a reproducible environment is to create a script that will generate the environment specification. We recommend creating a file named `generate_env.R` (or similar) in the project directory. This script will use the `rix()` function from the {rix} package to produce a `default.nix` file—a declarative specification that precisely defines all software dependencies required for the project.

For our simulation study, we implement the following environment specification, which can be found on the GitHub repository as a file named `generate_env.R`:

\small
```{r}
#| eval: false
#| echo: true
#library(rix)
rix(
  date = "2025-08-25",
  r_pkgs = c("rix", "quarto", "knitr", 
             "marginaleffects", "simhelpers", "ggplot2",
             "doParallel", "doRNG", "cowplot",
             "dplyr"),
  system_pkgs = c("quarto"),
  ide = "rstudio",
  project_path = ".",
  overwrite = TRUE
)
```
\normalsize

### The Environment Generation Script

The `rix()` function constructs this specification through a series of parameters that collectively describe the computational environment. Each parameter serves a distinct purpose in defining the environment's characteristics.

**Specifying the R version.** Researchers must first determine which version of R to use. This can be accomplished in two ways: The `r_ver` parameter accepts an exact version string (e.g., "4.3.3") or special designations such as "latest-upstream" for the most recent stable release. Alternatively, the `date` parameter specifies a particular date (e.g., "2024-11-15"), which ensures that R and all packages correspond to the versions available on that date. The date-based approach is generally preferable for reproducibility, as it captures a complete snapshot of the R ecosystem at a single point in time. For this tutorial, we use the `date` parameter to ensure temporal consistency across all software components.

**Declaring R package dependencies.** The `r_pkgs` parameter accepts a character vector listing all required R packages by their CRAN names. These packages will be installed from the version repository corresponding to the specified date or R version. It is important to list all packages that the analysis will load directly; dependencies of these packages are automatically resolved by Nix. For packages requiring specific versions not corresponding to the chosen date, researchers can specify exact versions using the syntax `"packagename@version"` (e.g., `"ggplot2@2.2.1"`). For packages available only on GitHub or other Git repositories, the `git_pkgs` parameter accepts a list structure containing repository URLs and specific commit hashes (see vignette `d1-installing-r-packages-in-a-nix-environment` for details). This ensures that exact development versions are obtained, which is particularly valuable when collaborating with package developers or requiring unreleased features.

**Including system-level dependencies.** Many R-based workflows require tools beyond R packages. The `system_pkgs` parameter specifies system-level software such as Quarto for document generation, Git for version control, or Pandoc for document conversion. The `tex_pkgs` parameter, similarly, lists LaTeX packages needed for PDF compilation. These can be added as needed for specific document formatting requirements. Critically, we include Quarto as a system package because this tutorial demonstrates full computational reproducibility—not merely of the simulation code, but of the complete manuscript itself. Our manuscript uses the `apaquarto` extension for APA formatting, stored in the project's `_extensions/` directory. Quarto extensions do not require explicit declaration in the Nix specification; when the `_extensions/` folder is committed to the repository, users building the environment automatically have access to these extensions.

**Multi-language environment support.** While this tutorial focuses on R, researchers working across multiple programming languages can include Python or Julia in their environments. The `py_conf` parameter accepts a list specifying a Python version and required packages (e.g., `py_conf = list(py_version = "3.12", py_pkgs = c("polars", "pandas"))`). Similarly, `jl_conf` enables Julia package installation. This capability is particularly useful for projects requiring statistical computing in R alongside machine learning pipelines in Python or numerical optimization in Julia.

**Configuring the development environment.** The `ide` parameter determines whether an integrated development environment should be included. Setting `ide = "rstudio"` installs a project-specific version of RStudio within the Nix environment. Note that on macOS, RStudio is only available through Nix for R versions 4.4.3 or later (or dates after 2025-02-28); for earlier versions, alternative editors must be used. Other supported IDEs include Positron (`ide = "positron"`), a next-generation data science IDE based on VS Code architecture, Visual Studio Code (`ide = "code"`), and command-line tools such as Radian (`ide = "radian"`). Each IDE installed via Nix is project-specific and will not interfere with system-wide installations. Researchers preferring to use an already-installed editor can set `ide = "none"` and configure their editor to interact with Nix shells (see vignette `e-configuring-ide` for configuration details).

**Setting file output parameters.** The `project_path` parameter indicates where the `default.nix` file should be written ("." denotes the current directory), while `overwrite` controls whether an existing file should be replaced. Setting `print = TRUE` displays the generated specification in the console for immediate verification.

### Generating the Environment Specification

Executing this script—either by running `Rscript generate_env.R` from the terminal or by sourcing it from within R using `source("generate_env.R")`—generates the `default.nix` file. This file serves as the formal, machine-readable specification of the computational environment. Importantly, `rix()` automatically invokes `rix_init()`, which creates a project-specific `.Rprofile` file that prevents package library conflicts and disables `install.packages()` to maintain environment integrity.

## Step III: Building and Using the Reproducible Environment

Once the `default.nix` file has been generated, the next step is to build the environment and use it to reproduce either the simulation analyses or the complete manuscript. This section demonstrates both workflows.

### Building the Environment

From the terminal, navigate to the project directory containing the `default.nix` file and execute:
```bash
nix-build
```

This command builds the environment according to the specification. The first execution will download and install all required packages, which may take a few minutes depending on network speed and system resources. Subsequent builds use cached packages and complete in seconds. Upon successful completion, a symbolic link named `result` appears in the project directory, pointing to the constructed environment in the Nix store.

To activate the environment, run:
```bash
nix-shell
```

This command drops the user into a shell where all specified packages and tools are available. The shell prompt typically changes to indicate that a Nix environment is active (e.g., `[nix-shell:~/project]$`). If RStudio was specified via `ide = "rstudio"`, it can be launched from within this shell by typing `rstudio`, ensuring it uses the project-specific R installation and package library.

### Reproducing the Simulation

As described before, our example contains multiple scripts. For streamlined execution, we provide a master script (`06_run_all.R`) that runs all simulation:

\small
```{r}
#| eval: false
#| echo: true

# required packages
library(marginaleffects); library(simhelpers)
library(doParallel); library(doRNG); library(ggplot2)

# step 1: run simulation (sources 01 and 02)
cat("Step 1: Running simulation...\n")
source("03_run_simulation.R")

# step 2: calculate performance metrics
cat("\nStep 2: Calculating performance metrics...\n")
source("04_performance_metrics.R")

# step 3: generate plots
cat("\nStep 3: Generating plots...\n")
source("05_plots.R")
```
\normalsize

Thus, to reproduce the simulation from within the Nix shell:
```bash
Rscript 06_run_all.R
```

This executes the complete simulation sequentially: first running the Monte Carlo replications which save results to `sim_results.rds`, then computing performance metrics and saving the summary table to `performance_summary.rds`, and finally generating all figures. Alternatively, individual scripts can be executed separately. The key advantage of executing within `nix-shell` is that all dependencies—R version, packages, and system tools—match exactly those specified in `default.nix`. However, while this linear structure is straightforward for moderate-scale simulations, more complex workflows could benefit from orchestration tools like `targets` (Landau, 2021), which manage dependencies automatically and ensure reproducibility. We will come back to this in the article. 

### Reproducing the Complete Manuscript

Beyond reproducing computational results, the Nix environment enables full manuscript reproducibility. The manuscript source file (`article.qmd`) combines narrative text, executable code chunks, and references to simulation outputs. In our specific case, we do not integrate the simulation run itself in the manuscript. We just load the obtained performance measures and integrate the code chunks that produce the plots (see Figure 1). To render the manuscript:

```bash
quarto render article.qmd 
```

This command executes all code chunks within the manuscript, incorporates results and figures, and produces a formatted PDF following APA style guidelines via the `apaquarto` extension. Because Quarto is included as a system package in our Nix specification, this rendering occurs within the reproducible environment, ensuring consistent output regardless of the host system's configuration.

```{r}
#| label: load-results
#| echo: false
#| message: false

summary_table <- readRDS("Simulation_Scripts/performance_summary.rds")

```

```{r}
#| label: fig-performance
#| fig-cap: "Performance of ACE estimator across sample sizes and confounding severity. Panel A shows relative bias, Panel B shows relative RMSE, Panel C shows coverage probability of 95% confidence intervals (dashed line at nominal 0.95 level), and Panel D shows average confidence interval width. Results demonstrate that model misspecification induces systematic bias that persists across sample sizes, while increasing sample size improves precision but not accuracy under misspecification."
#| fig-width: 10
#| fig-height: 8
#| echo: false
#| warning: false

# aanel A: Relative Bias
p_rel_bias <- ggplot(summary_table,
                     aes(x = n, y = rel_bias,
                         color = confound_label, group = confound_label)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Relative Bias",
       color = "Confounding\nnon-linearity",
       title = "A. Relative Bias") +
  theme_minimal() +
  theme(legend.position = "none")

# panel B: Relative RMSE
p_rel_rmse <- ggplot(summary_table,
                     aes(x = n, y = rel_rmse,
                         color = confound_label, group = confound_label)) +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Relative RMSE",
       color = "Confounding\nnon-linearity",
       title = "B. Relative RMSE") +
  theme_minimal() +
  theme(legend.position = "none")

# panel C: Coverage
p_coverage <- ggplot(summary_table,
                     aes(x = n, y = coverage,
                         color = confound_label, group = confound_label)) +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "gray50") +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Coverage of 95% CI",
       color = "Confounding\nnon-linearity",
       title = "C. Coverage Probability") +
  coord_cartesian(ylim = c(0, 1)) +
  theme_minimal() +
  theme(legend.position = "none")

# panel D: CI Width
p_width <- ggplot(summary_table,
                  aes(x = n, y = width,
                      color = confound_label, group = confound_label)) +
  geom_point(size = 3) +
  geom_line() +
  labs(x = "Sample size (n)",
       y = "Average CI Width",
       color = "Confounding\nnon-linearity",
       title = "D. Confidence Interval Width") +
  theme_minimal() +
  theme(legend.position = "none")

legend <- get_legend(
  p_rel_bias + theme(legend.position = "right")
)

# 2x2 grid 
plot_grid(
  plot_grid(p_rel_bias, p_rel_rmse, p_coverage, p_width, 
            ncol = 2, nrow = 2),
  legend,
  rel_widths = c(3, 0.4)
)
```

```{r}
#| label: tbl-results
#| tbl-cap: "Performance metrics for ACE estimator across simulation conditions"
#| echo: false

results_display <- summary_table %>%
  select(n, confound_label, rel_bias, rel_rmse, coverage, width) %>%
  mutate(
    `Sample Size` = n,
    `Confounding` = confound_label,
    `Relative Bias` = sprintf("%.3f", rel_bias),
    `Relative RMSE` = sprintf("%.3f", rel_rmse),
    `Coverage` = sprintf("%.3f", coverage),
    `CI Width` = sprintf("%.3f", width)
  ) %>%
  select(`Sample Size`, `Confounding`, `Relative Bias`, 
         `Relative RMSE`, `Coverage`, `CI Width`)

kable(results_display, align = "lccccc")
```

# Additional Considerations for Advanced Workflows

[...]

# Discussion

[...]

{{< pagebreak >}}

# References

::: {#refs}
:::

{{< include appendix_a.qmd >}}
